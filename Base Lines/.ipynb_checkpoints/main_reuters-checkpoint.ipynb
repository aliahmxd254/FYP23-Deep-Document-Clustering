{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# from tf_idf import wrapperFunction\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import adjusted_rand_score  # Import the Rand Index metric\n",
    "from collections import Counter\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.feature_extraction.text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = []  # all the content in the document\n",
    "doc_name = []  # name of the document\n",
    "files_path = []  # path to the documents\n",
    "lexical_chain = []  # list of lexical chains from each document\n",
    "total_features = []  # total number of features. 1652\n",
    "final_training_Features = []\n",
    "corpus = []\n",
    "doc_list_sequence = []\n",
    "\n",
    "data_dict = {}\n",
    "cluster_dict = {}\n",
    "mapped_data_dict = {}\n",
    "word_to_int = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDocuments(dir_name):\n",
    "    for Path in os.listdir(dir_name):\n",
    "        file_p = os.path.join(dir_name, Path)\n",
    "        with open(file_p, \"r\") as file:\n",
    "            FileContents = file.read()\n",
    "            doc_content.append(FileContents.lower())\n",
    "            doc_name.append(Path)\n",
    "            files_path.append(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Purity_Score(true_labels, predicted_labels):\n",
    "    total = len(true_labels)\n",
    "    num_clusters = len(set(predicted_labels))\n",
    "    \n",
    "    purity_sum = 0\n",
    "\n",
    "    for cluster in set(predicted_labels):\n",
    "        cluster_indices = [i for i, label in enumerate(predicted_labels) if label == cluster]\n",
    "        \n",
    "        if not cluster_indices:\n",
    "            continue  # Skip the cluster if there are no elements in it\n",
    "        \n",
    "        cluster_true_labels = [true_labels[i] for i in cluster_indices]\n",
    "        cluster_true_labels = [item for sublist in cluster_true_labels for item in sublist]  # Flatten the list of true labels\n",
    "        \n",
    "        class_counts = Counter(cluster_true_labels)\n",
    "        \n",
    "        # Check if class_counts is not empty before finding the maximum value\n",
    "        if class_counts:\n",
    "            max_class_count = max(class_counts.values())\n",
    "            purity_sum += max_class_count\n",
    "\n",
    "    return purity_sum / total\n",
    "\n",
    "\n",
    "# def Purity_Score(label_seq, pred_labels):\n",
    "#     # Calculate the confusion matrix to compare true labels and cluster assignments\n",
    "#     confusion = confusion_matrix(label_seq, pred_labels)\n",
    "#     # Calculate the purity\n",
    "#     purity = np.sum(np.max(confusion, axis=0)) / np.sum(confusion)\n",
    "#     return purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(X, true_labels, predicted_labels):\n",
    "    purity = Purity_Score(true_labels, predicted_labels)\n",
    "    silhouette = silhouette_score(X, predicted_labels, metric='euclidean')\n",
    "    ari = ari_score(true_labels, predicted_labels)\n",
    "    nmi = nmi_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f\"Purity: {purity}\")\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "    print(f\"ARI Score: {ari}\")\n",
    "    print(f\"NMI Score: {nmi}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveFeatures(X, file_name):\n",
    "    pickle_path = open(file_name, 'wb')\n",
    "    pickle.dump(X, pickle_path)\n",
    "    pickle_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadFeatures(file_name):\n",
    "    pickle_read = open(file_name, 'rb')\n",
    "    x = pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, remove_stopwords: bool) -> str:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n",
    "    if remove_stopwords:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        updated_tokens = []\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lower() in stopwords.words(\"english\"):\n",
    "                continue\n",
    "            else:\n",
    "                updated_tokens.append(lemmatizer.lemmatize(tokens[i].lower()))\n",
    "\n",
    "    return updated_tokens\n",
    "\n",
    "def buildRelation(nouns):\n",
    "    relation_list = defaultdict(list)\n",
    "\n",
    "    for k in range(len(nouns)):\n",
    "        relation = []\n",
    "        for syn in wn.synsets(nouns[k], pos=wn.NOUN):\n",
    "            for l in syn.lemmas():\n",
    "                relation.append(l.name())\n",
    "                if l.antonyms():\n",
    "                    relation.append(l.antonyms()[0].name())\n",
    "            for l in syn.hyponyms():\n",
    "                if l.hyponyms():\n",
    "                    relation.append(l.hyponyms()[0].name().split(\".\")[0])\n",
    "            for l in syn.hypernyms():\n",
    "                if l.hypernyms():\n",
    "                    relation.append(l.hypernyms()[0].name().split(\".\")[0])\n",
    "        relation_list[nouns[k]].append(relation)\n",
    "    return relation_list\n",
    "\n",
    "def buildLexicalChain(nouns, relation_list):\n",
    "    lexical = []\n",
    "    threshold = 0.5\n",
    "    for noun in nouns:\n",
    "        flag = 0\n",
    "        for j in range(len(lexical)):\n",
    "            if flag == 0:\n",
    "                for key in list(lexical[j]):\n",
    "                    if key == noun and flag == 0:\n",
    "                        lexical[j][noun] += 1\n",
    "                        flag = 1\n",
    "                    elif key in relation_list[noun][0] and flag == 0:\n",
    "                        syns1 = wn.synsets(key, pos=wn.NOUN)\n",
    "                        syns2 = wn.synsets(noun, pos=wn.NOUN)\n",
    "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
    "                            lexical[j][noun] = 1\n",
    "                            flag = 1\n",
    "                    elif noun in relation_list[key][0] and flag == 0:\n",
    "                        syns1 = wn.synsets(key, pos=wn.NOUN)\n",
    "                        syns2 = wn.synsets(noun, pos=wn.NOUN)\n",
    "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
    "                            lexical[j][noun] = 1\n",
    "                            flag = 1\n",
    "        if flag == 0:\n",
    "            dic_nuevo = {}\n",
    "            dic_nuevo[noun] = 1\n",
    "            lexical.append(dic_nuevo)\n",
    "            flag = 1\n",
    "    return lexical\n",
    "\n",
    "def eliminateWords(lexical):\n",
    "    final_chain = []\n",
    "    while lexical:\n",
    "        result = lexical.pop()\n",
    "        if len(result.keys()) == 1:\n",
    "            for value in result.values():\n",
    "                if value != 1:\n",
    "                    final_chain.append(result)\n",
    "        else:\n",
    "            final_chain.append(result)\n",
    "    return final_chain\n",
    "\n",
    "def PreprocessDocuments():\n",
    "    for i in files_path:\n",
    "        f = open(i, \"r\")\n",
    "        dataset = preprocess_text(f.read(), remove_stopwords=True)\n",
    "        # use lexical chains as the feature selection method\n",
    "        nouns = []\n",
    "        l = nltk.pos_tag(dataset)\n",
    "        for word, n in l:\n",
    "            if n == \"NN\" or n == \"NNS\" or n == \"NNP\" or n == \"NNPS\":\n",
    "                nouns.append(word)\n",
    "\n",
    "        relation = buildRelation(nouns)\n",
    "        lexical = buildLexicalChain(nouns, relation)\n",
    "        chain = eliminateWords(lexical)\n",
    "        lexical_chain.append(chain)\n",
    "\n",
    "    global total_features\n",
    "    for features in lexical_chain:\n",
    "        for docfeature in features:\n",
    "            total_features.extend(docfeature.keys())\n",
    "\n",
    "    total_features = list(set(total_features))\n",
    "\n",
    "    for feature in lexical_chain:\n",
    "        temp = []\n",
    "        # print(feature)\n",
    "        for j in total_features:\n",
    "            check = False\n",
    "            for f in feature:\n",
    "                if j in f:\n",
    "                    temp.append(f[j])\n",
    "                    check = True\n",
    "                    break\n",
    "            if not check:\n",
    "                temp.append(0)\n",
    "\n",
    "        final_training_Features.append(temp)\n",
    "\n",
    "def build_lexical_chains(doc):\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    chains = {}\n",
    "\n",
    "    for token, pos in pos_tags:\n",
    "        synsets = wn.synsets(token, pos=wn.NOUN)\n",
    "        for synset in synsets:\n",
    "            if synset not in chains:\n",
    "                chains[synset] = [token]\n",
    "            else:\n",
    "                chains[synset].append(token)\n",
    "\n",
    "    return chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetLabels(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 2:\n",
    "            key = parts[0]\n",
    "            values = parts[1:]\n",
    "            if len(values) == 1:\n",
    "                data_dict[key] = values[0]\n",
    "            else:\n",
    "                data_dict[key] = values\n",
    "                for value in values:\n",
    "                    cluster_dict[value] = None\n",
    "\n",
    "    word_list = list(cluster_dict.keys())\n",
    "\n",
    "    for i, word in enumerate(word_list):\n",
    "        word_to_int[word] = i\n",
    "\n",
    "    for key, value in data_dict.items():\n",
    "        if isinstance(value, list):\n",
    "            mapped_values = [word_to_int[word] for word in value]\n",
    "            mapped_data_dict[key] = mapped_values\n",
    "        else:\n",
    "            value_list = [value] if not isinstance(value, list) else value\n",
    "            mapped_values = [word_to_int[word] if word in word_to_int else word for word in value_list]\n",
    "            mapped_data_dict[key] = mapped_values\n",
    "\n",
    "    label_seq = list(mapped_data_dict.values())\n",
    "    # label_seq = [item for sublist in label_seq for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "# print(\"word list\",len(word_list),word_list)\n",
    "# print(\"word to int\", word_to_int)\n",
    "# print(\"mapped values\", mapped_values)\n",
    "# print(\"mapped_data_dict\", mapped_data_dict)\n",
    "    return label_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_path = \"D:\\FAST\\FYP\\FYP23-Deep-Document-Clustering\\Base Lines\\Reuters\\Training\"\n",
    "doc_path = os.getcwd() + \"\\Reuters\\Training\"\n",
    "ReadDocuments(doc_path)\n",
    "PreprocessDocuments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "normalized_features = normalizer.fit_transform(final_training_Features)\n",
    "# final_training_Features = final_training_Features / torch.norm(final_training_Features, dim=1)[:, None]      # GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveFeatures(final_training_Features, 'Reuters_Features_LexicalChains.pkl')\n",
    "SaveFeatures(normalized_features, 'Reuters_Normalized_Features_LexicalChains.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training_Features = ReadFeatures('Reuters_Features_LexicalChains.pkl')\n",
    "normalized_features = ReadFeatures('Reuters_Normalized_Features_LexicalChains.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum purity of 0.37022617723396367 found on random state 483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10788,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum purity of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpurity_collection[max_rand_state]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found on random state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_rand_state\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m lexicalChainsLabels \u001b[38;5;241m=\u001b[39m KMeans(n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(word_to_int\u001b[38;5;241m.\u001b[39mvalues())), random_state\u001b[38;5;241m=\u001b[39mmax_rand_state, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(pca_vecs)\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[1;32m---> 20\u001b[0m \u001b[43mEvaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpca_vecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlexicalChainsLabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mEvaluate\u001b[1;34m(X, true_labels, predicted_labels)\u001b[0m\n\u001b[0;32m      2\u001b[0m purity \u001b[38;5;241m=\u001b[39m Purity_Score(true_labels, predicted_labels)\n\u001b[0;32m      3\u001b[0m silhouette \u001b[38;5;241m=\u001b[39m silhouette_score(X, predicted_labels, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m ari \u001b[38;5;241m=\u001b[39m \u001b[43mari_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m nmi \u001b[38;5;241m=\u001b[39m nmi_score(true_labels, predicted_labels)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPurity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpurity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:434\u001b[0m, in \u001b[0;36madjusted_rand_score\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    337\u001b[0m     {\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m )\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjusted_rand_score\u001b[39m(labels_true, labels_pred):\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rand index adjusted for chance.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    The Rand Index computes a similarity measure between two clusterings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m      -0.5\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m     (tn, fp), (fn, tp) \u001b[38;5;241m=\u001b[39m \u001b[43mpair_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;66;03m# convert to Python integer types, to avoid overflow or underflow\u001b[39;00m\n\u001b[0;32m    436\u001b[0m     tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(tn), \u001b[38;5;28mint\u001b[39m(fp), \u001b[38;5;28mint\u001b[39m(fn), \u001b[38;5;28mint\u001b[39m(tp)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:240\u001b[0m, in \u001b[0;36mpair_confusion_matrix\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    174\u001b[0m     {\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m )\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpair_confusion_matrix\u001b[39m(labels_true, labels_pred):\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pair confusion matrix arising from two clusterings [1]_.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m    The pair confusion matrix :math:`C` computes a 2 by 2 similarity matrix\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    Note that the matrix is not symmetric.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     labels_true, labels_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_clusterings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint64(labels_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# Computation using the contingency data\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:43\u001b[0m, in \u001b[0;36mcheck_clusterings\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_clusterings\u001b[39m(labels_true, labels_pred):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that the labels arrays are 1D and of same dimension.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m        The predicted labels.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     labels_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     labels_pred \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m     51\u001b[0m         labels_pred,\n\u001b[0;32m     52\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m         ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     54\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m     )\n\u001b[0;32m     57\u001b[0m     type_label \u001b[38;5;241m=\u001b[39m type_of_target(labels_true)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10788,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "SumSqDis = []\n",
    "pca = PCA(n_components=30, random_state=42)\n",
    "pca_vecs = pca.fit_transform(final_training_Features)\n",
    "# pca_vecs = torch.tensor(pca_vecs, dtype=torch.float32).to(device)\n",
    "\n",
    "# 'D:\\FAST\\FYP\\FYP23-Deep-Document-Clustering\\Base Lines\\Reuters\\cats.txt'\n",
    "label_path = os.getcwd() + \"\\Reuters\\cats.txt\"\n",
    "label_seq = GetLabels(label_path)\n",
    "\n",
    "purity_collection = {}\n",
    "for i in range(500):\n",
    "    clusters = KMeans(n_init=\"auto\", n_clusters=len(list(word_to_int.values())), random_state=i, init=\"k-means++\").fit(pca_vecs).labels_\n",
    "    purity_collection[i] = Purity_Score(label_seq, clusters)\n",
    "\n",
    "max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "\n",
    "lexicalChainsLabels = KMeans(n_init=\"auto\", n_clusters=len(list(word_to_int.values())), random_state=max_rand_state, init=\"k-means++\").fit(pca_vecs).labels_\n",
    "\n",
    "Evaluate(pca_vecs, label_seq, lexicalChainsLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_wordnet(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    return len(synsets) > 0\n",
    "\n",
    "def contains_number(word):\n",
    "    for char in word:\n",
    "        if char.isnumeric():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def min_length_word(word):\n",
    "    if  len(word) in [1,2]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def custom_preprocessor(text):\n",
    "    lematizer = WordNetLemmatizer()\n",
    "    used_terms = {} # keep track of which terms have already been considered\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        if (not contains_number(word)) and (not min_length_word(word)) and (word not in stopwords.words('english')) and (in_wordnet(word)):\n",
    "            lema_word = lematizer.lemmatize(word)\n",
    "            if lema_word in used_terms.keys():\n",
    "                continue\n",
    "            else:\n",
    "                used_terms[lema_word] = 0\n",
    "                filtered_tokens.append(lema_word)\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "def print_terms(terms):\n",
    "    for term in terms:\n",
    "        print(term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_Labels(X, n, rstate_limit, true_labels):\n",
    "    # find centoids which give maximum purity\n",
    "    purity_collection = {}\n",
    "    for i in range(rstate_limit):\n",
    "        clusters = KMeans(n_init='auto', n_clusters=n, random_state=i, init='k-means++').fit(X).labels_\n",
    "        purity_collection[i] = Purity_Score(true_labels, clusters)\n",
    "    \n",
    "    max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "    print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "\n",
    "    # Create a KMeans model\n",
    "    cluster_assignments = KMeans(n_init='auto', n_clusters=n, random_state=max_rand_state, init='k-means++').fit(X).labels_\n",
    "\n",
    "    return cluster_assignments\n",
    "\n",
    "def print_results(true_labels, predicted_labels, X):\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"Purity: {Purity_Score(true_labels, predicted_labels)}\")\n",
    "    print(f\"Silhouette Score: {silhouette_score(X, predicted_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', preprocessor=custom_preprocessor)\n",
    "X = vectorizer.fit_transform(doc_content)\n",
    "\n",
    "SaveFeatures('Reuters_TFIDF_Features')\n",
    "\n",
    "#true_labels = GetLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum purity of 0.36772339636633294 found on random state 67\n",
      "RESULTS:\n",
      "Purity: 0.36772339636633294\n",
      "Silhouette Score: -0.006047238747527097\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = KMeans_Labels(X, 5, 700, label_seq)\n",
    "Evaluate(X, label_seq, predicted_labels)\n",
    "\n",
    "#print_results(, predicted_labels, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfLabels = predicted_labels\n",
    "tfidfMatrix = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_consensus_matrix(labels1, labels2):\n",
    "    n = len(labels1)\n",
    "    consensus_matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            #Calculate the Jaccard similarity between the two label sets\n",
    "            intersection = np.intersect1d(labels1[i], labels2[j])\n",
    "            union = np.union1d(labels1[i], labels2[j])\n",
    "            agreement = len(intersection) / len(union)\n",
    "        \n",
    "\n",
    "            consensus_matrix[i, j] = agreement\n",
    "            consensus_matrix[j, i] = agreement\n",
    "\n",
    "    return consensus_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum purity of 0.36763070077864296 found on random state 2\n",
      "Purity Score:  0.36763070077864296\n",
      "Sillhouette Coefficient:  -0.11535524251258987\n"
     ]
    }
   ],
   "source": [
    "consensus_matrix = calculate_consensus_matrix(tfidfLabels, lexicalChainsLabels)\n",
    "\n",
    "n_clusters = 5  # You can adjust this as needed\n",
    "purity_collection = {}\n",
    "for i in range(500):\n",
    "    clusters = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=i).fit(1 - consensus_matrix).labels_\n",
    "    purity_collection[i] = Purity_Score(label_seq, clusters)\n",
    "\n",
    "max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "spectral_labels = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=max_rand_state).fit(1 - consensus_matrix).labels_\n",
    "print(\"Purity Score: \", Purity_Score(label_seq, spectral_labels))\n",
    "print(\"Sillhouette Coefficient: \",metrics.silhouette_score(pca_vecs, spectral_labels, metric=\"euclidean\"),)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum purity of 0.3674453096032629 found on random state 0\n",
      "Purity:  0.3674453096032629\n",
      "Sillhouette Coefficient:  0.7289370934632332\n"
     ]
    }
   ],
   "source": [
    "num_topics = 5  # Adjust as needed\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "topic_proportions = lda.fit_transform(tfidfMatrix)\n",
    "\n",
    "combined_features = np.hstack((spectral_labels.reshape(-1, 1), topic_proportions))\n",
    "\n",
    "normalize_combined_features = Normalizer().fit_transform(combined_features)\n",
    "\n",
    "topic_purity_collection = {}\n",
    "for i in range(500):\n",
    "    topic_clusters = (\n",
    "        KMeans(n_init=\"auto\", n_clusters=5, random_state=i, init=\"k-means++\")\n",
    "        .fit(normalize_combined_features)\n",
    "        .labels_\n",
    "    )\n",
    "    topic_purity_collection[i] = Purity_Score(label_seq, topic_clusters)\n",
    "\n",
    "topic_max_rand_state = max(topic_purity_collection, key=topic_purity_collection.get)\n",
    "print(f\"Maximum purity of {topic_purity_collection[topic_max_rand_state]} found on random state {topic_max_rand_state}\")\n",
    "max_labels = (\n",
    "    KMeans(\n",
    "        n_init=\"auto\", n_clusters=5, random_state=topic_max_rand_state, init=\"k-means++\"\n",
    "    )\n",
    "    .fit(normalize_combined_features)\n",
    "    .labels_\n",
    ")\n",
    "print(\"Purity: \", Purity_Score(label_seq, max_labels))\n",
    "print(\"Sillhouette Coefficient: \",metrics.silhouette_score(normalize_combined_features, max_labels, metric=\"euclidean\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
