{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d6fa05-2120-4935-91a9-8f11fc7c7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.feature_extraction.text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692bb7ed-6854-4788-93dd-40dc0a514afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = []  # all the content in the document\n",
    "doc_name = []  # name of the document\n",
    "files_path = []  # path to the documents\n",
    "lexical_chain = []  # list of lexical chains from each document\n",
    "total_features = []  # total number of features. 1652\n",
    "final_training_Features = [] # to store features for training\n",
    "corpus = [] # to store all text\n",
    "doc_list_sequence = [] # store sequence of document read\n",
    "actual_labels = {} # to store actual cluster of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecde5cc8-33af-4671-9734-86abac1a0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDocuments(dir_name):\n",
    "    current_file_id = 0\n",
    "    current_dir_id = 0\n",
    "    for Path in os.listdir(dir_name):\n",
    "        sub_dir_path = os.path.join(dir_name, Path)\n",
    "        for sub_dir_files in os.listdir(sub_dir_path):\n",
    "            file_p = os.path.join(sub_dir_path, sub_dir_files)\n",
    "            with open(file_p, \"r\") as file:\n",
    "                FileContents = file.read()\n",
    "                doc_content.append(FileContents.lower())\n",
    "                doc_name.append(current_file_id)\n",
    "                actual_labels[current_file_id] = current_dir_id \n",
    "                current_file_id+=1\n",
    "                files_path.append(file_p)\n",
    "        current_dir_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64065066-ba95-4db5-b17d-25727c6a7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Purity_Score(label_seq, pred_labels):\n",
    "    # Calculate the confusion matrix to compare true labels and cluster assignments\n",
    "    confusion = confusion_matrix(label_seq, pred_labels)\n",
    "    # Calculate the purity\n",
    "    purity = np.sum(np.max(confusion, axis=0)) / np.sum(confusion)\n",
    "    return purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fbbc58-ea2c-4710-96c6-f81990fc72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(X, true_labels, predicted_labels):\n",
    "    purity = Purity_Score(true_labels, predicted_labels)\n",
    "    silhouette = silhouette_score(X, predicted_labels, metric='euclidean')\n",
    "    ari = ari_score(true_labels, predicted_labels)\n",
    "    nmi = nmi_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f\"Purity: {purity}\")\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "    print(f\"ARI Score: {ari}\")\n",
    "    print(f\"NMI Score: {nmi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df18ea0-a008-421e-8ce6-1f92784ba519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveFeatures(X, file_name):\n",
    "    pickle_path = open(file_name, 'wb')\n",
    "    pickle.dump(X, pickle_path)\n",
    "    pickle_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62fe004-9c29-468b-be60-8770b7bcdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadFeatures(file_name):\n",
    "    pickle_read = open(file_name, 'rb')\n",
    "    x = pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949897b-65ad-4e8e-8929-dacbf8173c2f",
   "metadata": {},
   "source": [
    "# Lexical Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d62e9d21-2bb7-4d7b-98ff-536c81b2b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess_text(text: str, remove_stopwords: bool) -> str:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n",
    "    if remove_stopwords:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        updated_tokens = []\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lower() in stopwords.words(\"english\"):\n",
    "                continue\n",
    "            else:\n",
    "                updated_tokens.append(lemmatizer.lemmatize(tokens[i].lower()))\n",
    "\n",
    "    return updated_tokens\n",
    "\n",
    "def buildRelation(nouns):\n",
    "    relation_list = defaultdict(list)\n",
    "\n",
    "    for k in range(len(nouns)):\n",
    "        relation = []\n",
    "        for syn in wn.synsets(nouns[k], pos=wn.NOUN):\n",
    "            for l in syn.lemmas():\n",
    "                relation.append(l.name())\n",
    "                if l.antonyms():\n",
    "                    relation.append(l.antonyms()[0].name())\n",
    "            for l in syn.hyponyms():\n",
    "                if l.hyponyms():\n",
    "                    relation.append(l.hyponyms()[0].name().split(\".\")[0])\n",
    "            for l in syn.hypernyms():\n",
    "                if l.hypernyms():\n",
    "                    relation.append(l.hypernyms()[0].name().split(\".\")[0])\n",
    "        relation_list[nouns[k]].append(relation)\n",
    "    return relation_list\n",
    "\n",
    "def buildLexicalChain(nouns, relation_list):\n",
    "    lexical = []\n",
    "    threshold = 0.5\n",
    "    for noun in nouns:\n",
    "        flag = 0\n",
    "        for j in range(len(lexical)):\n",
    "            if flag == 0:\n",
    "                for key in list(lexical[j]):\n",
    "                    if key == noun and flag == 0:\n",
    "                        lexical[j][noun] += 1\n",
    "                        flag = 1\n",
    "                    elif key in relation_list[noun][0] and flag == 0:\n",
    "                        syns1 = wn.synsets(key, pos=wn.NOUN)\n",
    "                        syns2 = wn.synsets(noun, pos=wn.NOUN)\n",
    "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
    "                            lexical[j][noun] = 1\n",
    "                            flag = 1\n",
    "                    elif noun in relation_list[key][0] and flag == 0:\n",
    "                        syns1 = wn.synsets(key, pos=wn.NOUN)\n",
    "                        syns2 = wn.synsets(noun, pos=wn.NOUN)\n",
    "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
    "                            lexical[j][noun] = 1\n",
    "                            flag = 1\n",
    "        if flag == 0:\n",
    "            dic_nuevo = {}\n",
    "            dic_nuevo[noun] = 1\n",
    "            lexical.append(dic_nuevo)\n",
    "            flag = 1\n",
    "    return lexical\n",
    "\n",
    "def eliminateWords(lexical):\n",
    "    final_chain = []\n",
    "    while lexical:\n",
    "        result = lexical.pop()\n",
    "        if len(result.keys()) == 1:\n",
    "            for value in result.values():\n",
    "                if value != 1:\n",
    "                    final_chain.append(result)\n",
    "        else:\n",
    "            final_chain.append(result)\n",
    "    return final_chain\n",
    "\n",
    "def PreprocessDocuments():\n",
    "    for i in files_path:\n",
    "        f = open(i, \"r\")\n",
    "        dataset = preprocess_text(f.read(), remove_stopwords=True)\n",
    "        # use lexical chains as the feature selection method\n",
    "        nouns = []\n",
    "        l = nltk.pos_tag(dataset)\n",
    "        for word, n in l:\n",
    "            if n == \"NN\" or n == \"NNS\" or n == \"NNP\" or n == \"NNPS\":\n",
    "                nouns.append(word)\n",
    "\n",
    "        relation = buildRelation(nouns)\n",
    "        lexical = buildLexicalChain(nouns, relation)\n",
    "        chain = eliminateWords(lexical)\n",
    "        lexical_chain.append(chain)\n",
    "\n",
    "    global total_features\n",
    "    for features in lexical_chain:\n",
    "        for docfeature in features:\n",
    "            total_features.extend(docfeature.keys())\n",
    "\n",
    "    total_features = list(set(total_features))\n",
    "\n",
    "    for feature in lexical_chain:\n",
    "        temp = []\n",
    "        # print(feature)\n",
    "        for j in total_features:\n",
    "            check = False\n",
    "            for f in feature:\n",
    "                if j in f:\n",
    "                    temp.append(f[j])\n",
    "                    check = True\n",
    "                    break\n",
    "            if not check:\n",
    "                temp.append(0)\n",
    "\n",
    "        final_training_Features.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4e253b-0ddb-4e1a-b6ed-aa720ffbe8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_path = os.getcwd() + \"\\BBC\"\n",
    "ReadDocuments(BBC_path)\n",
    "#PreprocessDocuments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "436299e9-4ad5-4ce8-b7bd-5b223dde8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save training features\n",
    "# import pickle\n",
    "# pickle_path = open('BBC_Features_LexicalChains.pkl', 'wb')\n",
    "# pickle.dump(final_training_Features, pickle_path)\n",
    "# pickle_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a30a901-3f24-4c68-94cd-8d2ed52b1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save normalized features\n",
    "#normalizer = Normalizer()\n",
    "#normalize_features = normalizer.fit_transform(final_training_Features)\n",
    "#pickle_path = open('BBC_Normalized_Features_LexicalChains.pkl', 'wb')\n",
    "#pickle.dump(normalize_features, pickle_path)\n",
    "#pickle_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba00972-4256-4bb5-b57f-d0d2d2516cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read final training features:\n",
    "pickle_read = open('BBC_Features_LexicalChains.pkl', 'rb')\n",
    "final_training_Features = pickle.load(pickle_read)\n",
    "pickle_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5b2298-7c05-45a6-88fa-4f24b49c211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read normalized features:\n",
    "pickle_read = open('BBC_Normalized_Features_LexicalChains.pkl', 'rb')\n",
    "normalize_features = pickle.load(pickle_read)\n",
    "pickle_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "56427626-cede-4112-adb8-d0e69d53cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality can be reduced to check in increase in accuracy\n",
    "pca = PCA(n_components=30, random_state=42)\n",
    "pca_vecs = pca.fit_transform(normalize_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6901177c-4c9a-4ce5-9ed0-d0ace39ec79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.7478651685393258\n",
      "Silhouette Score: -0.024339736196491817\n",
      "ARI Score: 0.5064025551370372\n",
      "NMI Score: 0.5210485295651401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "label_seq = list(actual_labels.values())\n",
    "\n",
    "# purity_collection = {}\n",
    "# for i in range(610):\n",
    "#     clusters = KMeans(n_init=\"auto\", n_clusters=5, random_state=i, init=\"k-means++\").fit(normalize_features).labels_\n",
    "#     purity_collection[i] = Purity_Score(label_seq, clusters)\n",
    "\n",
    "# #highest found on 606 using normalized features\n",
    "# max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "# print(\n",
    "#     f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\"\n",
    "# )\n",
    "\n",
    "lexicalChainsLabels = KMeans(n_init=\"auto\", n_clusters=5, random_state=606, init=\"k-means++\").fit(normalize_features).labels_\n",
    "\n",
    "Evaluate(final_training_Features, label_seq, lexicalChainsLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4802f5d-970e-4c02-a8fc-e84e31e98658",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f9f406b-16a0-42ae-847a-d3458d125955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_wordnet(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    return len(synsets) > 0\n",
    "\n",
    "def contains_number(word):\n",
    "    for char in word:\n",
    "        if char.isnumeric():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def min_length_word(word):\n",
    "    if  len(word) in [1,2]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def custom_preprocessor(text):\n",
    "    lematizer = WordNetLemmatizer()\n",
    "    used_terms = {} # keep track of which terms have already been considered\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        if (not contains_number(word)) and (not min_length_word(word)) and (word not in stopwords.words('english')) and (in_wordnet(word)):\n",
    "            lema_word = lematizer.lemmatize(word)\n",
    "            if lema_word in used_terms.keys():\n",
    "                continue\n",
    "            else:\n",
    "                used_terms[lema_word] = 0\n",
    "                filtered_tokens.append(lema_word)\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "def print_terms(terms):\n",
    "    for term in terms:\n",
    "        print(term)\n",
    "\n",
    "def KMeans_Labels(X, n, rstate_limit, true_labels):\n",
    "\n",
    "    # Specify the number of clusters (you can choose an appropriate value)\n",
    "    num_clusters = n\n",
    "    \n",
    "    # find centoids which give maximum purity\n",
    "    purity_collection = {}\n",
    "    for i in range(rstate_limit):\n",
    "        clusters = KMeans(n_init='auto', n_clusters=num_clusters, random_state=i, init='k-means++').fit(X).labels_\n",
    "        purity_collection[i] = Purity_Score(true_labels, clusters)\n",
    "    \n",
    "    max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "    print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "\n",
    "    # Create a KMeans model\n",
    "    kmeans = KMeans(n_init='auto', n_clusters=num_clusters, random_state=max_rand_state, init='k-means++')\n",
    "    # Fit the KMeans model to the TF-IDF data\n",
    "    kmeans.fit(X)\n",
    "    # Get the cluster assignments for each document\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    \n",
    "    return cluster_assignments\n",
    "\n",
    "def print_results(true_labels, predicted_labels, X):\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"Purity: {Purity_Score(true_labels, predicted_labels)}\")\n",
    "    print(f\"Silhouette Score: {silhouette_score(X, predicted_labels)}\")\n",
    "\n",
    "def wrapperFunction():\n",
    "    # ReadDocuments(os.getcwd() + \"\\BBC\")\n",
    "    # vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', preprocessor=custom_preprocessor)\n",
    "    # print(\"Building Features...\")\n",
    "    # X = vectorizer.fit_transform(doc_content)\n",
    "\n",
    "    # # save tdidf-features\n",
    "    # print(\"Saving tf-idf features\")\n",
    "    # pickle_write = open('BBC_Features_TFIDF.pkl', 'wb')\n",
    "    # pickle.dump(X, pickle_write)\n",
    "    # pickle_write.close()\n",
    "\n",
    "    #load tdidf features\n",
    "\n",
    "    X = ReadFeatures('BBC_Features_TFIDF.pkl')\n",
    "    \n",
    "    true_labels = list(actual_labels.values())\n",
    "    print(len(true_labels))\n",
    "    print(\"Applying KMeans Clustering...\")\n",
    "    predicted_labels = KMeans_Labels(X, 5, 650, true_labels)\n",
    "    Evaluate(X, true_labels, predicted_labels)\n",
    "    return predicted_labels, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce86ae8-45cc-4301-869b-c3870654ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "Applying KMeans Clustering...\n",
      "Maximum purity of 0.9622471910112359 found on random state 499\n",
      "Purity: 0.9622471910112359\n",
      "Silhouette Score: 0.010218972318231987\n",
      "ARI Score: 0.911712231307629\n",
      "NMI Score: 0.8785596848846153\n"
     ]
    }
   ],
   "source": [
    "doc_content = []\n",
    "tfidfLabels, tfidfMatrix = wrapperFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043dcbd-3d81-4a72-aa1b-362f7551a794",
   "metadata": {},
   "source": [
    "# Consensus Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71f51f22-fbb1-4455-823f-0bc4a56c655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_consensus_matrix(labels1, labels2):\n",
    "    n = len(labels1)\n",
    "    consensus_matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            #Calculate the Jaccard similarity between the two label sets\n",
    "            intersection = np.intersect1d(labels1[i], labels2[j])\n",
    "            union = np.union1d(labels1[i], labels2[j])\n",
    "            agreement = len(intersection) / len(union)\n",
    "        \n",
    "\n",
    "            consensus_matrix[i, j] = agreement\n",
    "            consensus_matrix[j, i] = agreement\n",
    "\n",
    "    return consensus_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc866df4-a4d5-4e51-9e64-2df8e4a26197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Consensus Matrix...\n",
      "Applying Consensus Clustering....\n",
      "Maximum purity of 0.5995505617977528 found on random state 29\n",
      "Purity: 0.5995505617977528\n",
      "Silhouette Score: 0.24106704926477115\n",
      "ARI Score: 0.3616399420946902\n",
      "NMI Score: 0.5473986830618421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Consensus Matrix...\")\n",
    "consensus_matrix = calculate_consensus_matrix(tfidfLabels, lexicalChainsLabels)\n",
    "\n",
    "n_clusters = 5  # You can adjust this as needed\n",
    "random_state_limit = 700\n",
    "\n",
    "purity_collection = {}\n",
    "print(\"Applying Consensus Clustering....\")\n",
    "for i in range(random_state_limit):\n",
    "    clusters = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=i).fit(1 - consensus_matrix).labels_\n",
    "    purity_collection[i] = Purity_Score(label_seq, clusters)\n",
    "\n",
    "max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "spectral_labels = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=max_rand_state).fit(1 - consensus_matrix).labels_\n",
    "\n",
    "Evaluate(1-consensus_matrix, label_seq, spectral_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727efcb-eefc-4b2a-88db-2f7c1301f58d",
   "metadata": {},
   "source": [
    "# Topical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96745671-8a1e-43ca-b8f4-f7a96fc4ad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum purity of 0.8588764044943821 found on random state 71\n",
      "Purity: 0.8588764044943821\n",
      "Silhouette Score: 0.6609660724161398\n",
      "ARI Score: 0.7186189217262748\n",
      "NMI Score: 0.7144144650712116\n"
     ]
    }
   ],
   "source": [
    "num_topics = 5  # Adjust as needed\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "\n",
    "lda.fit(tfidfMatrix)\n",
    "\n",
    "# Get the topic assignments for each document\n",
    "topic_labels = lda.transform(tfidfMatrix).argmax(axis=1)\n",
    "\n",
    "combined_labels = [lexicalChainsLabels, tfidfLabels, topic_labels]\n",
    "combined_labels = list(map(list, zip(*combined_labels)))\n",
    "\n",
    "normalize_combined_features = Normalizer().fit_transform(combined_labels)\n",
    "topic_purity_collection = {}\n",
    "for i in range(600):\n",
    "    topic_clusters = (KMeans(n_init=\"auto\", n_clusters=5, random_state=i, init=\"k-means++\").fit(normalize_combined_features).labels_)\n",
    "    topic_purity_collection[i] = Purity_Score(label_seq, topic_clusters)\n",
    "\n",
    "topic_max_rand_state = max(topic_purity_collection, key=topic_purity_collection.get)\n",
    "print(f\"Maximum purity of {topic_purity_collection[topic_max_rand_state]} found on random state {topic_max_rand_state}\")\n",
    "max_labels = (KMeans(n_init=\"auto\", n_clusters=5, random_state=topic_max_rand_state, init=\"k-means++\").fit(normalize_combined_features)\n",
    "              .labels_)\n",
    "\n",
    "Evaluate(normalize_combined_features, label_seq, max_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
