{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d6fa05-2120-4935-91a9-8f11fc7c7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.feature_extraction.text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692bb7ed-6854-4788-93dd-40dc0a514afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = []  # all the content in the document\n",
    "doc_name = []  # name of the document\n",
    "files_path = []  # path to the documents\n",
    "lexical_chain = []  # list of lexical chains from each document\n",
    "total_features = []  # total number of features. 1652\n",
    "final_training_Features = [] # to store features for training\n",
    "corpus = [] # to store all text\n",
    "doc_list_sequence = [] # store sequence of document read\n",
    "actual_labels = {} # to store actual cluster of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecde5cc8-33af-4671-9734-86abac1a0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDocuments(dir_name):\n",
    "    current_file_id = 0\n",
    "    current_dir_id = 0\n",
    "    for Path in os.listdir(dir_name):\n",
    "        sub_dir_path = os.path.join(dir_name, Path)\n",
    "        for sub_dir_files in os.listdir(sub_dir_path):\n",
    "            file_p = os.path.join(sub_dir_path, sub_dir_files)\n",
    "            with open(file_p, \"r\") as file:\n",
    "                FileContents = file.read()\n",
    "                doc_content.append(FileContents.lower())\n",
    "                doc_name.append(current_file_id)\n",
    "                actual_labels[current_file_id] = current_dir_id \n",
    "                current_file_id+=1\n",
    "                files_path.append(file_p)\n",
    "        current_dir_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64065066-ba95-4db5-b17d-25727c6a7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Purity_Score(label_seq, pred_labels):\n",
    "    # Calculate the confusion matrix to compare true labels and cluster assignments\n",
    "    confusion = confusion_matrix(label_seq, pred_labels)\n",
    "    # Calculate the purity\n",
    "    purity = np.sum(np.max(confusion, axis=0)) / np.sum(confusion)\n",
    "    return purity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949897b-65ad-4e8e-8929-dacbf8173c2f",
   "metadata": {},
   "source": [
    "# Lexical Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62e9d21-2bb7-4d7b-98ff-536c81b2b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess_text(text: str, remove_stopwords: bool) -> str:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n",
    "    if remove_stopwords:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        updated_tokens = []\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lower() in stopwords.words(\"english\"):\n",
    "                continue\n",
    "            else:\n",
    "                updated_tokens.append(lemmatizer.lemmatize(tokens[i].lower()))\n",
    "\n",
    "    return updated_tokens\n",
    "\n",
    "def buildRelation(nouns):\n",
    "    relation_list = defaultdict(list)\n",
    "\n",
    "    for k in range(len(nouns)):\n",
    "        relation = []\n",
    "        for syn in wn.synsets(nouns[k], pos=wn.NOUN):\n",
    "            for l in syn.lemmas():\n",
    "                relation.append(l.name())\n",
    "                if l.antonyms():\n",
    "                    relation.append(l.antonyms()[0].name())\n",
    "            for l in syn.hyponyms():\n",
    "                if l.hyponyms():\n",
    "                    relation.append(l.hyponyms()[0].name().split(\".\")[0])\n",
    "            for l in syn.hypernyms():\n",
    "                if l.hypernyms():\n",
    "                    relation.append(l.hypernyms()[0].name().split(\".\")[0])\n",
    "        relation_list[nouns[k]].append(relation)\n",
    "    return relation_list\n",
    "\n",
    "def buildLexicalChain(nouns, relation_list):\n",
    "    lexical = []\n",
    "    threshold = 0.5\n",
    "    for noun in nouns:\n",
    "        flag = 0\n",
    "        for j in range(len(lexical)):\n",
    "            if flag == 0:\n",
    "                for key in list(lexical[j]):\n",
    "                    if key == noun and flag == 0:\n",
    "                        lexical[j][noun] += 1\n",
    "                        flag = 1\n",
    "                    elif key in relation_list[noun][0] and flag == 0:\n",
    "                        syns1 = wn.synsets(key, pos=wn.NOUN)\n",
    "                        syns2 = wn.synsets(noun, pos=wn.NOUN)\n",
    "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
    "                            lexical[j][noun] = 1\n",
    "                            flag = 1\n",
    "                    elif noun in relation_list[key][0] and flag == 0:\n",
    "                        syns1 = wn.synsets(key, pos=wn.NOUN)\n",
    "                        syns2 = wn.synsets(noun, pos=wn.NOUN)\n",
    "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
    "                            lexical[j][noun] = 1\n",
    "                            flag = 1\n",
    "        if flag == 0:\n",
    "            dic_nuevo = {}\n",
    "            dic_nuevo[noun] = 1\n",
    "            lexical.append(dic_nuevo)\n",
    "            flag = 1\n",
    "    return lexical\n",
    "\n",
    "def eliminateWords(lexical):\n",
    "    final_chain = []\n",
    "    while lexical:\n",
    "        result = lexical.pop()\n",
    "        if len(result.keys()) == 1:\n",
    "            for value in result.values():\n",
    "                if value != 1:\n",
    "                    final_chain.append(result)\n",
    "        else:\n",
    "            final_chain.append(result)\n",
    "    return final_chain\n",
    "\n",
    "def PreprocessDocuments():\n",
    "    for i in files_path:\n",
    "        f = open(i, \"r\")\n",
    "        dataset = preprocess_text(f.read(), remove_stopwords=True)\n",
    "        # use lexical chains as the feature selection method\n",
    "        nouns = []\n",
    "        l = nltk.pos_tag(dataset)\n",
    "        for word, n in l:\n",
    "            if n == \"NN\" or n == \"NNS\" or n == \"NNP\" or n == \"NNPS\":\n",
    "                nouns.append(word)\n",
    "\n",
    "        relation = buildRelation(nouns)\n",
    "        lexical = buildLexicalChain(nouns, relation)\n",
    "        chain = eliminateWords(lexical)\n",
    "        lexical_chain.append(chain)\n",
    "\n",
    "    global total_features\n",
    "    for features in lexical_chain:\n",
    "        for docfeature in features:\n",
    "            total_features.extend(docfeature.keys())\n",
    "\n",
    "    total_features = list(set(total_features))\n",
    "\n",
    "    for feature in lexical_chain:\n",
    "        temp = []\n",
    "        # print(feature)\n",
    "        for j in total_features:\n",
    "            check = False\n",
    "            for f in feature:\n",
    "                if j in f:\n",
    "                    temp.append(f[j])\n",
    "                    check = True\n",
    "                    break\n",
    "            if not check:\n",
    "                temp.append(0)\n",
    "\n",
    "        final_training_Features.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4e253b-0ddb-4e1a-b6ed-aa720ffbe8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_path = os.getcwd() + \"\\BBC\"\n",
    "ReadDocuments(BBC_path)\n",
    "#PreprocessDocuments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "436299e9-4ad5-4ce8-b7bd-5b223dde8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save training features\n",
    "# import pickle\n",
    "# pickle_path = open('BBC_Features_LexicalChains.pkl', 'wb')\n",
    "# pickle.dump(final_training_Features, pickle_path)\n",
    "# pickle_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a30a901-3f24-4c68-94cd-8d2ed52b1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save normalized features\n",
    "#normalizer = Normalizer()\n",
    "#normalize_features = normalizer.fit_transform(final_training_Features)\n",
    "#pickle_path = open('BBC_Normalized_Features_LexicalChains.pkl', 'wb')\n",
    "#pickle.dump(normalize_features, pickle_path)\n",
    "#pickle_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba00972-4256-4bb5-b57f-d0d2d2516cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read final training features:\n",
    "pickle_read = open('BBC_Features_LexicalChains.pkl', 'rb')\n",
    "final_training_Features = pickle.load(pickle_read)\n",
    "pickle_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe5b2298-7c05-45a6-88fa-4f24b49c211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read normalized features:\n",
    "pickle_read = open('BBC_Normalized_Features_LexicalChains.pkl', 'rb')\n",
    "normalize_features = pickle.load(pickle_read)\n",
    "pickle_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "56427626-cede-4112-adb8-d0e69d53cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality can be reduced to check in increase in accuracy\n",
    "pca = PCA(n_components=30, random_state=42)\n",
    "pca_vecs = pca.fit_transform(normalize_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6901177c-4c9a-4ce5-9ed0-d0ace39ec79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means lables using lexical chains: [3 3 3 ... 2 2 1]\n",
      "      \n",
      "Purity 0.7478651685393258\n",
      "      \n",
      "Silhoutte Score: -0.024339736196491817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "label_seq = list(actual_labels.values())\n",
    "# purity_collection = {}\n",
    "# for i in range(610):\n",
    "#     clusters = KMeans(n_init=\"auto\", n_clusters=5, random_state=i, init=\"k-means++\").fit(normalize_features).labels_\n",
    "#     purity_collection[i] = Purity_Score(label_seq, clusters)\n",
    "\n",
    "# #highest found on 606 using normalized features\n",
    "# max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "# print(\n",
    "#     f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\"\n",
    "# )\n",
    "\n",
    "lexicalChainsLabels = KMeans(n_init=\"auto\", n_clusters=5, random_state=606, init=\"k-means++\").fit(normalize_features).labels_\n",
    "\n",
    "print(f\"\"\"K-means lables using lexical chains: {lexicalChainsLabels}\n",
    "      \\nPurity {Purity_Score(label_seq, lexicalChainsLabels)}\n",
    "      \\nSilhoutte Score: {metrics.silhouette_score(final_training_Features, lexicalChainsLabels, metric='euclidean')}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0eacb8-03ee-43e4-8077-3488ca67144a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 6276)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4802f5d-970e-4c02-a8fc-e84e31e98658",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9f406b-16a0-42ae-847a-d3458d125955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_wordnet(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    return len(synsets) > 0\n",
    "\n",
    "def contains_number(word):\n",
    "    for char in word:\n",
    "        if char.isnumeric():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def min_length_word(word):\n",
    "    if  len(word) in [1,2]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def custom_preprocessor(text):\n",
    "    lematizer = WordNetLemmatizer()\n",
    "    used_terms = {} # keep track of which terms have already been considered\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        if (not contains_number(word)) and (not min_length_word(word)) and (word not in stopwords.words('english')) and (in_wordnet(word)):\n",
    "            lema_word = lematizer.lemmatize(word)\n",
    "            if lema_word in used_terms.keys():\n",
    "                continue\n",
    "            else:\n",
    "                used_terms[lema_word] = 0\n",
    "                filtered_tokens.append(lema_word)\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "def print_terms(terms):\n",
    "    for term in terms:\n",
    "        print(term)\n",
    "\n",
    "def KMeans_Labels(X, n, rstate_limit, true_labels):\n",
    "\n",
    "    # Specify the number of clusters (you can choose an appropriate value)\n",
    "    num_clusters = n\n",
    "    \n",
    "    # find centoids which give maximum purity\n",
    "    purity_collection = {}\n",
    "    for i in range(rstate_limit):\n",
    "        clusters = KMeans(n_init='auto', n_clusters=num_clusters, random_state=i, init='k-means++').fit(X).labels_\n",
    "        purity_collection[i] = Purity_Score(true_labels, clusters)\n",
    "    \n",
    "    max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "    print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "\n",
    "    # Create a KMeans model\n",
    "    kmeans = KMeans(n_init='auto', n_clusters=num_clusters, random_state=max_rand_state, init='k-means++')\n",
    "    # Fit the KMeans model to the TF-IDF data\n",
    "    kmeans.fit(X)\n",
    "    # Get the cluster assignments for each document\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    \n",
    "    return cluster_assignments\n",
    "\n",
    "def print_results(true_labels, predicted_labels, X):\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"Purity: {Purity_Score(true_labels, predicted_labels)}\")\n",
    "    print(f\"Silhouette Score: {silhouette_score(X, predicted_labels)}\")\n",
    "\n",
    "def wrapperFunction():\n",
    "    # ReadDocuments(os.getcwd() + \"\\BBC\")\n",
    "    # vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', preprocessor=custom_preprocessor)\n",
    "    # print(\"Building Features...\")\n",
    "    # X = vectorizer.fit_transform(doc_content)\n",
    "\n",
    "    # # save tdidf-features\n",
    "    # print(\"Saving tf-idf features\")\n",
    "    # pickle_write = open('BBC_Features_TFIDF.pkl', 'wb')\n",
    "    # pickle.dump(X, pickle_write)\n",
    "    # pickle_write.close()\n",
    "\n",
    "    #load tdidf features\n",
    "    pickle_read = open('BBC_Features_TFIDF.pkl', 'rb')\n",
    "    X = pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "    \n",
    "    \n",
    "    true_labels = list(actual_labels.values())\n",
    "    print(len(true_labels))\n",
    "    print(\"Applying KMeans Clustering...\")\n",
    "    predicted_labels = KMeans_Labels(X, 5, 650, true_labels)\n",
    "    print_results(true_labels, predicted_labels, X)\n",
    "    return predicted_labels, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce86ae8-45cc-4301-869b-c3870654ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "Applying KMeans Clustering...\n",
      "Maximum purity of 0.9622471910112359 found on random state 499\n",
      "RESULTS:\n",
      "Purity: 0.9622471910112359\n",
      "Silhouette Score: 0.010218972318231987\n"
     ]
    }
   ],
   "source": [
    "doc_content = []\n",
    "tfidfLabels, tfidfMatrix = wrapperFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043dcbd-3d81-4a72-aa1b-362f7551a794",
   "metadata": {},
   "source": [
    "# Consensus Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f51f22-fbb1-4455-823f-0bc4a56c655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_consensus_matrix(labels1, labels2):\n",
    "    n = len(labels1)\n",
    "    consensus_matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            #Calculate the Jaccard similarity between the two label sets\n",
    "            intersection = np.intersect1d(labels1[i], labels2[j])\n",
    "            union = np.union1d(labels1[i], labels2[j])\n",
    "            agreement = len(intersection) / len(union)\n",
    "        \n",
    "\n",
    "            consensus_matrix[i, j] = agreement\n",
    "            consensus_matrix[j, i] = agreement\n",
    "\n",
    "    return consensus_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc866df4-a4d5-4e51-9e64-2df8e4a26197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Consensus Matrix...\n",
      "Trying clustering on random state 0..\n",
      "Trying clustering on random state 1..\n",
      "Trying clustering on random state 2..\n",
      "Trying clustering on random state 3..\n",
      "Trying clustering on random state 4..\n",
      "Trying clustering on random state 5..\n",
      "Trying clustering on random state 6..\n",
      "Trying clustering on random state 7..\n",
      "Trying clustering on random state 8..\n",
      "Trying clustering on random state 9..\n",
      "Trying clustering on random state 10..\n",
      "Trying clustering on random state 11..\n",
      "Trying clustering on random state 12..\n",
      "Trying clustering on random state 13..\n",
      "Trying clustering on random state 14..\n",
      "Trying clustering on random state 15..\n",
      "Trying clustering on random state 16..\n",
      "Trying clustering on random state 17..\n",
      "Trying clustering on random state 18..\n",
      "Trying clustering on random state 19..\n",
      "Trying clustering on random state 20..\n",
      "Trying clustering on random state 21..\n",
      "Trying clustering on random state 22..\n",
      "Trying clustering on random state 23..\n",
      "Trying clustering on random state 24..\n",
      "Trying clustering on random state 25..\n",
      "Trying clustering on random state 26..\n",
      "Trying clustering on random state 27..\n",
      "Trying clustering on random state 28..\n",
      "Trying clustering on random state 29..\n",
      "Trying clustering on random state 30..\n",
      "Trying clustering on random state 31..\n",
      "Trying clustering on random state 32..\n",
      "Trying clustering on random state 33..\n",
      "Trying clustering on random state 34..\n",
      "Trying clustering on random state 35..\n",
      "Trying clustering on random state 36..\n",
      "Trying clustering on random state 37..\n",
      "Trying clustering on random state 38..\n",
      "Trying clustering on random state 39..\n",
      "Trying clustering on random state 40..\n",
      "Trying clustering on random state 41..\n",
      "Trying clustering on random state 42..\n",
      "Trying clustering on random state 43..\n",
      "Trying clustering on random state 44..\n",
      "Trying clustering on random state 45..\n",
      "Trying clustering on random state 46..\n",
      "Trying clustering on random state 47..\n",
      "Trying clustering on random state 48..\n",
      "Trying clustering on random state 49..\n",
      "Trying clustering on random state 50..\n",
      "Trying clustering on random state 51..\n",
      "Trying clustering on random state 52..\n",
      "Trying clustering on random state 53..\n",
      "Trying clustering on random state 54..\n",
      "Trying clustering on random state 55..\n",
      "Trying clustering on random state 56..\n",
      "Trying clustering on random state 57..\n",
      "Trying clustering on random state 58..\n",
      "Trying clustering on random state 59..\n",
      "Trying clustering on random state 60..\n",
      "Trying clustering on random state 61..\n",
      "Trying clustering on random state 62..\n",
      "Trying clustering on random state 63..\n",
      "Trying clustering on random state 64..\n",
      "Trying clustering on random state 65..\n",
      "Trying clustering on random state 66..\n",
      "Trying clustering on random state 67..\n",
      "Trying clustering on random state 68..\n",
      "Trying clustering on random state 69..\n",
      "Trying clustering on random state 70..\n",
      "Trying clustering on random state 71..\n",
      "Trying clustering on random state 72..\n",
      "Trying clustering on random state 73..\n",
      "Trying clustering on random state 74..\n",
      "Trying clustering on random state 75..\n",
      "Trying clustering on random state 76..\n",
      "Trying clustering on random state 77..\n",
      "Trying clustering on random state 78..\n",
      "Trying clustering on random state 79..\n",
      "Trying clustering on random state 80..\n",
      "Trying clustering on random state 81..\n",
      "Trying clustering on random state 82..\n",
      "Trying clustering on random state 83..\n",
      "Trying clustering on random state 84..\n",
      "Trying clustering on random state 85..\n",
      "Trying clustering on random state 86..\n",
      "Trying clustering on random state 87..\n",
      "Trying clustering on random state 88..\n",
      "Trying clustering on random state 89..\n",
      "Trying clustering on random state 90..\n",
      "Trying clustering on random state 91..\n",
      "Trying clustering on random state 92..\n",
      "Trying clustering on random state 93..\n",
      "Trying clustering on random state 94..\n",
      "Trying clustering on random state 95..\n",
      "Trying clustering on random state 96..\n",
      "Trying clustering on random state 97..\n",
      "Trying clustering on random state 98..\n",
      "Trying clustering on random state 99..\n",
      "Trying clustering on random state 100..\n",
      "Trying clustering on random state 101..\n",
      "Trying clustering on random state 102..\n",
      "Trying clustering on random state 103..\n",
      "Trying clustering on random state 104..\n",
      "Trying clustering on random state 105..\n",
      "Trying clustering on random state 106..\n",
      "Trying clustering on random state 107..\n",
      "Trying clustering on random state 108..\n",
      "Trying clustering on random state 109..\n",
      "Trying clustering on random state 110..\n",
      "Trying clustering on random state 111..\n",
      "Trying clustering on random state 112..\n",
      "Trying clustering on random state 113..\n",
      "Trying clustering on random state 114..\n",
      "Trying clustering on random state 115..\n",
      "Trying clustering on random state 116..\n",
      "Trying clustering on random state 117..\n",
      "Trying clustering on random state 118..\n",
      "Trying clustering on random state 119..\n",
      "Trying clustering on random state 120..\n",
      "Trying clustering on random state 121..\n",
      "Trying clustering on random state 122..\n",
      "Trying clustering on random state 123..\n",
      "Trying clustering on random state 124..\n",
      "Trying clustering on random state 125..\n",
      "Trying clustering on random state 126..\n",
      "Trying clustering on random state 127..\n",
      "Trying clustering on random state 128..\n",
      "Trying clustering on random state 129..\n",
      "Trying clustering on random state 130..\n",
      "Trying clustering on random state 131..\n",
      "Trying clustering on random state 132..\n",
      "Trying clustering on random state 133..\n",
      "Trying clustering on random state 134..\n",
      "Trying clustering on random state 135..\n",
      "Trying clustering on random state 136..\n",
      "Trying clustering on random state 137..\n",
      "Trying clustering on random state 138..\n",
      "Trying clustering on random state 139..\n",
      "Trying clustering on random state 140..\n",
      "Trying clustering on random state 141..\n",
      "Trying clustering on random state 142..\n",
      "Trying clustering on random state 143..\n",
      "Trying clustering on random state 144..\n",
      "Trying clustering on random state 145..\n",
      "Trying clustering on random state 146..\n",
      "Trying clustering on random state 147..\n",
      "Trying clustering on random state 148..\n",
      "Trying clustering on random state 149..\n",
      "Trying clustering on random state 150..\n",
      "Trying clustering on random state 151..\n",
      "Trying clustering on random state 152..\n",
      "Trying clustering on random state 153..\n",
      "Trying clustering on random state 154..\n",
      "Trying clustering on random state 155..\n",
      "Trying clustering on random state 156..\n",
      "Trying clustering on random state 157..\n",
      "Trying clustering on random state 158..\n",
      "Trying clustering on random state 159..\n",
      "Trying clustering on random state 160..\n",
      "Trying clustering on random state 161..\n",
      "Trying clustering on random state 162..\n",
      "Trying clustering on random state 163..\n",
      "Trying clustering on random state 164..\n",
      "Trying clustering on random state 165..\n",
      "Trying clustering on random state 166..\n",
      "Trying clustering on random state 167..\n",
      "Trying clustering on random state 168..\n",
      "Trying clustering on random state 169..\n",
      "Trying clustering on random state 170..\n",
      "Trying clustering on random state 171..\n",
      "Trying clustering on random state 172..\n",
      "Trying clustering on random state 173..\n",
      "Trying clustering on random state 174..\n",
      "Trying clustering on random state 175..\n",
      "Trying clustering on random state 176..\n",
      "Trying clustering on random state 177..\n",
      "Trying clustering on random state 178..\n",
      "Trying clustering on random state 179..\n",
      "Trying clustering on random state 180..\n",
      "Trying clustering on random state 181..\n",
      "Trying clustering on random state 182..\n",
      "Trying clustering on random state 183..\n",
      "Trying clustering on random state 184..\n",
      "Trying clustering on random state 185..\n",
      "Trying clustering on random state 186..\n",
      "Trying clustering on random state 187..\n",
      "Trying clustering on random state 188..\n",
      "Trying clustering on random state 189..\n",
      "Trying clustering on random state 190..\n",
      "Trying clustering on random state 191..\n",
      "Trying clustering on random state 192..\n",
      "Trying clustering on random state 193..\n",
      "Trying clustering on random state 194..\n",
      "Trying clustering on random state 195..\n",
      "Trying clustering on random state 196..\n",
      "Trying clustering on random state 197..\n",
      "Trying clustering on random state 198..\n",
      "Trying clustering on random state 199..\n",
      "Trying clustering on random state 200..\n",
      "Trying clustering on random state 201..\n",
      "Trying clustering on random state 202..\n",
      "Trying clustering on random state 203..\n",
      "Trying clustering on random state 204..\n",
      "Trying clustering on random state 205..\n",
      "Trying clustering on random state 206..\n",
      "Trying clustering on random state 207..\n",
      "Trying clustering on random state 208..\n",
      "Trying clustering on random state 209..\n",
      "Trying clustering on random state 210..\n",
      "Trying clustering on random state 211..\n",
      "Trying clustering on random state 212..\n",
      "Trying clustering on random state 213..\n",
      "Trying clustering on random state 214..\n",
      "Trying clustering on random state 215..\n",
      "Trying clustering on random state 216..\n",
      "Trying clustering on random state 217..\n",
      "Trying clustering on random state 218..\n",
      "Trying clustering on random state 219..\n",
      "Trying clustering on random state 220..\n",
      "Trying clustering on random state 221..\n",
      "Trying clustering on random state 222..\n",
      "Trying clustering on random state 223..\n",
      "Trying clustering on random state 224..\n",
      "Trying clustering on random state 225..\n",
      "Trying clustering on random state 226..\n",
      "Trying clustering on random state 227..\n",
      "Trying clustering on random state 228..\n",
      "Trying clustering on random state 229..\n",
      "Trying clustering on random state 230..\n",
      "Trying clustering on random state 231..\n",
      "Trying clustering on random state 232..\n",
      "Trying clustering on random state 233..\n",
      "Trying clustering on random state 234..\n",
      "Trying clustering on random state 235..\n",
      "Trying clustering on random state 236..\n",
      "Trying clustering on random state 237..\n",
      "Trying clustering on random state 238..\n",
      "Trying clustering on random state 239..\n",
      "Trying clustering on random state 240..\n",
      "Trying clustering on random state 241..\n",
      "Trying clustering on random state 242..\n",
      "Trying clustering on random state 243..\n",
      "Trying clustering on random state 244..\n",
      "Trying clustering on random state 245..\n",
      "Trying clustering on random state 246..\n",
      "Trying clustering on random state 247..\n",
      "Trying clustering on random state 248..\n",
      "Trying clustering on random state 249..\n",
      "Trying clustering on random state 250..\n",
      "Trying clustering on random state 251..\n",
      "Trying clustering on random state 252..\n",
      "Trying clustering on random state 253..\n",
      "Trying clustering on random state 254..\n",
      "Trying clustering on random state 255..\n",
      "Trying clustering on random state 256..\n",
      "Trying clustering on random state 257..\n",
      "Trying clustering on random state 258..\n",
      "Trying clustering on random state 259..\n",
      "Trying clustering on random state 260..\n",
      "Trying clustering on random state 261..\n",
      "Trying clustering on random state 262..\n",
      "Trying clustering on random state 263..\n",
      "Trying clustering on random state 264..\n",
      "Trying clustering on random state 265..\n",
      "Trying clustering on random state 266..\n",
      "Trying clustering on random state 267..\n",
      "Trying clustering on random state 268..\n",
      "Trying clustering on random state 269..\n",
      "Trying clustering on random state 270..\n",
      "Trying clustering on random state 271..\n",
      "Trying clustering on random state 272..\n",
      "Trying clustering on random state 273..\n",
      "Trying clustering on random state 274..\n",
      "Trying clustering on random state 275..\n",
      "Trying clustering on random state 276..\n",
      "Trying clustering on random state 277..\n",
      "Trying clustering on random state 278..\n",
      "Trying clustering on random state 279..\n",
      "Trying clustering on random state 280..\n",
      "Trying clustering on random state 281..\n",
      "Trying clustering on random state 282..\n",
      "Trying clustering on random state 283..\n",
      "Trying clustering on random state 284..\n",
      "Trying clustering on random state 285..\n",
      "Trying clustering on random state 286..\n",
      "Trying clustering on random state 287..\n",
      "Trying clustering on random state 288..\n",
      "Trying clustering on random state 289..\n",
      "Trying clustering on random state 290..\n",
      "Trying clustering on random state 291..\n",
      "Trying clustering on random state 292..\n",
      "Trying clustering on random state 293..\n",
      "Trying clustering on random state 294..\n",
      "Trying clustering on random state 295..\n",
      "Trying clustering on random state 296..\n",
      "Trying clustering on random state 297..\n",
      "Trying clustering on random state 298..\n",
      "Trying clustering on random state 299..\n",
      "Trying clustering on random state 300..\n",
      "Trying clustering on random state 301..\n",
      "Trying clustering on random state 302..\n",
      "Trying clustering on random state 303..\n",
      "Trying clustering on random state 304..\n",
      "Trying clustering on random state 305..\n",
      "Trying clustering on random state 306..\n",
      "Trying clustering on random state 307..\n",
      "Trying clustering on random state 308..\n",
      "Trying clustering on random state 309..\n",
      "Trying clustering on random state 310..\n",
      "Trying clustering on random state 311..\n",
      "Trying clustering on random state 312..\n",
      "Trying clustering on random state 313..\n",
      "Trying clustering on random state 314..\n",
      "Trying clustering on random state 315..\n",
      "Trying clustering on random state 316..\n",
      "Trying clustering on random state 317..\n",
      "Trying clustering on random state 318..\n",
      "Trying clustering on random state 319..\n",
      "Trying clustering on random state 320..\n",
      "Trying clustering on random state 321..\n",
      "Trying clustering on random state 322..\n",
      "Trying clustering on random state 323..\n",
      "Trying clustering on random state 324..\n",
      "Trying clustering on random state 325..\n",
      "Trying clustering on random state 326..\n",
      "Trying clustering on random state 327..\n",
      "Trying clustering on random state 328..\n",
      "Trying clustering on random state 329..\n",
      "Trying clustering on random state 330..\n",
      "Trying clustering on random state 331..\n",
      "Trying clustering on random state 332..\n",
      "Trying clustering on random state 333..\n",
      "Trying clustering on random state 334..\n",
      "Trying clustering on random state 335..\n",
      "Trying clustering on random state 336..\n",
      "Trying clustering on random state 337..\n",
      "Trying clustering on random state 338..\n",
      "Trying clustering on random state 339..\n",
      "Trying clustering on random state 340..\n",
      "Trying clustering on random state 341..\n",
      "Trying clustering on random state 342..\n",
      "Trying clustering on random state 343..\n",
      "Trying clustering on random state 344..\n",
      "Trying clustering on random state 345..\n",
      "Trying clustering on random state 346..\n",
      "Trying clustering on random state 347..\n",
      "Trying clustering on random state 348..\n",
      "Trying clustering on random state 349..\n",
      "Trying clustering on random state 350..\n",
      "Trying clustering on random state 351..\n",
      "Trying clustering on random state 352..\n",
      "Trying clustering on random state 353..\n",
      "Trying clustering on random state 354..\n",
      "Trying clustering on random state 355..\n",
      "Trying clustering on random state 356..\n",
      "Trying clustering on random state 357..\n",
      "Trying clustering on random state 358..\n",
      "Trying clustering on random state 359..\n",
      "Trying clustering on random state 360..\n",
      "Trying clustering on random state 361..\n",
      "Trying clustering on random state 362..\n",
      "Trying clustering on random state 363..\n",
      "Trying clustering on random state 364..\n",
      "Trying clustering on random state 365..\n",
      "Trying clustering on random state 366..\n",
      "Trying clustering on random state 367..\n",
      "Trying clustering on random state 368..\n",
      "Trying clustering on random state 369..\n",
      "Trying clustering on random state 370..\n",
      "Trying clustering on random state 371..\n",
      "Trying clustering on random state 372..\n",
      "Trying clustering on random state 373..\n",
      "Trying clustering on random state 374..\n",
      "Trying clustering on random state 375..\n",
      "Trying clustering on random state 376..\n",
      "Trying clustering on random state 377..\n",
      "Trying clustering on random state 378..\n",
      "Trying clustering on random state 379..\n",
      "Trying clustering on random state 380..\n",
      "Trying clustering on random state 381..\n",
      "Trying clustering on random state 382..\n",
      "Trying clustering on random state 383..\n",
      "Trying clustering on random state 384..\n",
      "Trying clustering on random state 385..\n",
      "Trying clustering on random state 386..\n",
      "Trying clustering on random state 387..\n",
      "Trying clustering on random state 388..\n",
      "Trying clustering on random state 389..\n",
      "Trying clustering on random state 390..\n",
      "Trying clustering on random state 391..\n",
      "Trying clustering on random state 392..\n",
      "Trying clustering on random state 393..\n",
      "Trying clustering on random state 394..\n",
      "Trying clustering on random state 395..\n",
      "Trying clustering on random state 396..\n",
      "Trying clustering on random state 397..\n",
      "Trying clustering on random state 398..\n",
      "Trying clustering on random state 399..\n",
      "Trying clustering on random state 400..\n",
      "Trying clustering on random state 401..\n",
      "Trying clustering on random state 402..\n",
      "Trying clustering on random state 403..\n",
      "Trying clustering on random state 404..\n",
      "Trying clustering on random state 405..\n",
      "Trying clustering on random state 406..\n",
      "Trying clustering on random state 407..\n",
      "Trying clustering on random state 408..\n",
      "Trying clustering on random state 409..\n",
      "Trying clustering on random state 410..\n",
      "Trying clustering on random state 411..\n",
      "Trying clustering on random state 412..\n",
      "Trying clustering on random state 413..\n",
      "Trying clustering on random state 414..\n",
      "Trying clustering on random state 415..\n",
      "Trying clustering on random state 416..\n",
      "Trying clustering on random state 417..\n",
      "Trying clustering on random state 418..\n",
      "Trying clustering on random state 419..\n",
      "Trying clustering on random state 420..\n",
      "Trying clustering on random state 421..\n",
      "Trying clustering on random state 422..\n",
      "Trying clustering on random state 423..\n",
      "Trying clustering on random state 424..\n",
      "Trying clustering on random state 425..\n",
      "Trying clustering on random state 426..\n",
      "Trying clustering on random state 427..\n",
      "Trying clustering on random state 428..\n",
      "Trying clustering on random state 429..\n",
      "Trying clustering on random state 430..\n",
      "Trying clustering on random state 431..\n",
      "Trying clustering on random state 432..\n",
      "Trying clustering on random state 433..\n",
      "Trying clustering on random state 434..\n",
      "Trying clustering on random state 435..\n",
      "Trying clustering on random state 436..\n",
      "Trying clustering on random state 437..\n",
      "Trying clustering on random state 438..\n",
      "Trying clustering on random state 439..\n",
      "Trying clustering on random state 440..\n",
      "Trying clustering on random state 441..\n",
      "Trying clustering on random state 442..\n",
      "Trying clustering on random state 443..\n",
      "Trying clustering on random state 444..\n",
      "Trying clustering on random state 445..\n",
      "Trying clustering on random state 446..\n",
      "Trying clustering on random state 447..\n",
      "Trying clustering on random state 448..\n",
      "Trying clustering on random state 449..\n",
      "Trying clustering on random state 450..\n",
      "Trying clustering on random state 451..\n",
      "Trying clustering on random state 452..\n",
      "Trying clustering on random state 453..\n",
      "Trying clustering on random state 454..\n",
      "Trying clustering on random state 455..\n",
      "Trying clustering on random state 456..\n",
      "Trying clustering on random state 457..\n",
      "Trying clustering on random state 458..\n",
      "Trying clustering on random state 459..\n",
      "Trying clustering on random state 460..\n",
      "Trying clustering on random state 461..\n",
      "Trying clustering on random state 462..\n",
      "Trying clustering on random state 463..\n",
      "Trying clustering on random state 464..\n",
      "Trying clustering on random state 465..\n",
      "Trying clustering on random state 466..\n",
      "Trying clustering on random state 467..\n",
      "Trying clustering on random state 468..\n",
      "Trying clustering on random state 469..\n",
      "Trying clustering on random state 470..\n",
      "Trying clustering on random state 471..\n",
      "Trying clustering on random state 472..\n",
      "Trying clustering on random state 473..\n",
      "Trying clustering on random state 474..\n",
      "Trying clustering on random state 475..\n",
      "Trying clustering on random state 476..\n",
      "Trying clustering on random state 477..\n",
      "Trying clustering on random state 478..\n",
      "Trying clustering on random state 479..\n",
      "Trying clustering on random state 480..\n",
      "Trying clustering on random state 481..\n",
      "Trying clustering on random state 482..\n",
      "Trying clustering on random state 483..\n",
      "Trying clustering on random state 484..\n",
      "Trying clustering on random state 485..\n",
      "Trying clustering on random state 486..\n",
      "Trying clustering on random state 487..\n",
      "Trying clustering on random state 488..\n",
      "Trying clustering on random state 489..\n",
      "Trying clustering on random state 490..\n",
      "Trying clustering on random state 491..\n",
      "Trying clustering on random state 492..\n",
      "Trying clustering on random state 493..\n",
      "Trying clustering on random state 494..\n",
      "Trying clustering on random state 495..\n",
      "Trying clustering on random state 496..\n",
      "Trying clustering on random state 497..\n",
      "Trying clustering on random state 498..\n",
      "Trying clustering on random state 499..\n",
      "Trying clustering on random state 500..\n",
      "Trying clustering on random state 501..\n",
      "Trying clustering on random state 502..\n",
      "Trying clustering on random state 503..\n",
      "Trying clustering on random state 504..\n",
      "Trying clustering on random state 505..\n",
      "Trying clustering on random state 506..\n",
      "Trying clustering on random state 507..\n",
      "Trying clustering on random state 508..\n",
      "Trying clustering on random state 509..\n",
      "Trying clustering on random state 510..\n",
      "Trying clustering on random state 511..\n",
      "Trying clustering on random state 512..\n",
      "Trying clustering on random state 513..\n",
      "Trying clustering on random state 514..\n",
      "Trying clustering on random state 515..\n",
      "Trying clustering on random state 516..\n",
      "Trying clustering on random state 517..\n",
      "Trying clustering on random state 518..\n",
      "Trying clustering on random state 519..\n",
      "Trying clustering on random state 520..\n",
      "Trying clustering on random state 521..\n",
      "Trying clustering on random state 522..\n",
      "Trying clustering on random state 523..\n",
      "Trying clustering on random state 524..\n",
      "Trying clustering on random state 525..\n",
      "Trying clustering on random state 526..\n",
      "Trying clustering on random state 527..\n",
      "Trying clustering on random state 528..\n",
      "Trying clustering on random state 529..\n",
      "Trying clustering on random state 530..\n",
      "Trying clustering on random state 531..\n",
      "Trying clustering on random state 532..\n",
      "Trying clustering on random state 533..\n",
      "Trying clustering on random state 534..\n",
      "Trying clustering on random state 535..\n",
      "Trying clustering on random state 536..\n",
      "Trying clustering on random state 537..\n",
      "Trying clustering on random state 538..\n",
      "Trying clustering on random state 539..\n",
      "Trying clustering on random state 540..\n",
      "Trying clustering on random state 541..\n",
      "Trying clustering on random state 542..\n",
      "Trying clustering on random state 543..\n",
      "Trying clustering on random state 544..\n",
      "Trying clustering on random state 545..\n",
      "Trying clustering on random state 546..\n",
      "Trying clustering on random state 547..\n",
      "Trying clustering on random state 548..\n",
      "Trying clustering on random state 549..\n",
      "Trying clustering on random state 550..\n",
      "Trying clustering on random state 551..\n",
      "Trying clustering on random state 552..\n",
      "Trying clustering on random state 553..\n",
      "Trying clustering on random state 554..\n",
      "Trying clustering on random state 555..\n",
      "Trying clustering on random state 556..\n",
      "Trying clustering on random state 557..\n",
      "Trying clustering on random state 558..\n",
      "Trying clustering on random state 559..\n",
      "Trying clustering on random state 560..\n",
      "Trying clustering on random state 561..\n",
      "Trying clustering on random state 562..\n",
      "Trying clustering on random state 563..\n",
      "Trying clustering on random state 564..\n",
      "Trying clustering on random state 565..\n",
      "Trying clustering on random state 566..\n",
      "Trying clustering on random state 567..\n",
      "Trying clustering on random state 568..\n",
      "Trying clustering on random state 569..\n",
      "Trying clustering on random state 570..\n",
      "Trying clustering on random state 571..\n",
      "Trying clustering on random state 572..\n",
      "Trying clustering on random state 573..\n",
      "Trying clustering on random state 574..\n",
      "Trying clustering on random state 575..\n",
      "Trying clustering on random state 576..\n",
      "Trying clustering on random state 577..\n",
      "Trying clustering on random state 578..\n",
      "Trying clustering on random state 579..\n",
      "Trying clustering on random state 580..\n",
      "Trying clustering on random state 581..\n",
      "Trying clustering on random state 582..\n",
      "Trying clustering on random state 583..\n",
      "Trying clustering on random state 584..\n",
      "Trying clustering on random state 585..\n",
      "Trying clustering on random state 586..\n",
      "Trying clustering on random state 587..\n",
      "Trying clustering on random state 588..\n",
      "Trying clustering on random state 589..\n",
      "Trying clustering on random state 590..\n",
      "Trying clustering on random state 591..\n",
      "Trying clustering on random state 592..\n",
      "Trying clustering on random state 593..\n",
      "Trying clustering on random state 594..\n",
      "Trying clustering on random state 595..\n",
      "Trying clustering on random state 596..\n",
      "Trying clustering on random state 597..\n",
      "Trying clustering on random state 598..\n",
      "Trying clustering on random state 599..\n",
      "Maximum purity of 0.5995505617977528 found on random state 29\n",
      "Purity Score:  0.5995505617977528\n",
      "Sillhouette Coefficient:  0.004260656809315734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Consensus Matrix...\")\n",
    "consensus_matrix = calculate_consensus_matrix(tfidfLabels, lexicalChainsLabels)\n",
    "\n",
    "n_clusters = 5  # You can adjust this as needed\n",
    "purity_collection = {}\n",
    "for i in range(600):\n",
    "    print(f\"Trying clustering on random state {i}..\")\n",
    "    clusters = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=i).fit(1 - consensus_matrix).labels_\n",
    "    purity_collection[i] = Purity_Score(label_seq, clusters)\n",
    "\n",
    "max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "spectral_labels = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=max_rand_state).fit(1 - consensus_matrix).labels_\n",
    "print(\"Purity Score: \", Purity_Score(label_seq, spectral_labels))\n",
    "print(\"Sillhouette Coefficient: \",metrics.silhouette_score(normalize_features, spectral_labels, metric=\"euclidean\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd2e10d1-4c30-49b9-8e79-2d8e6efdd503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading\n",
    "\n",
    "# # release unrequired memory\n",
    "# # del doc_content\n",
    "# # del tfidfMatrix\n",
    "# # del normalize_features\n",
    "# # del final_training_Features\n",
    "# # gc.collect()\n",
    "\n",
    "# threads = []\n",
    "# n_clusters = 5  # You can adjust this as needed\n",
    "# purity_collection = {}\n",
    "# lock = threading.Lock()\n",
    "# random_state_count = 200\n",
    "\n",
    "# def SpectralClusteringParallel(consensus_matrix, n_clust, rand_state):\n",
    "#     print(f\"Trying clustering on random state {i}..\")\n",
    "#     specteral_ = SpectralClustering(n_clusters=n_clust, affinity=\"precomputed\", random_state=rand_state)\n",
    "#     clusters = specteral_.fit(1 - consensus_matrix).labels_\n",
    "#     purity_collection[rand_state] = Purity_Score(label_seq, clusters)\n",
    "#     print(f\"Thread {rand_state} complete\")\n",
    "\n",
    "# print(\"Building Consensus Matrix...\")\n",
    "# consensus_matrix = calculate_consensus_matrix(tfidfLabels, lexicalChainsLabels)\n",
    "\n",
    "# for i in range(random_state_count):\n",
    "#     threads.append(threading.Thread(target=SpectralClusteringParallel, args=(consensus_matrix, n_clusters, i)))\n",
    "#     threads[i].start()\n",
    "    \n",
    "#     #clusters = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=i).fit(1 - consensus_matrix).labels_\n",
    "#     #purity_collection[i] = Purity_Score(label_seq, clusters)\n",
    "\n",
    "# for i in range(random_state_count):\n",
    "#     threads[i].join()\n",
    "\n",
    "# max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "# print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "# spectral_labels = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", random_state=max_rand_state).fit(1 - consensus_matrix).labels_\n",
    "# print(\"Purity Score: \", Purity_Score(label_seq, spectral_labels))\n",
    "# print(\"Sillhouette Coefficient: \",metrics.silhouette_score(pca_vecs, spectral_labels, metric=\"euclidean\"),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727efcb-eefc-4b2a-88db-2f7c1301f58d",
   "metadata": {},
   "source": [
    "# Topical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96745671-8a1e-43ca-b8f4-f7a96fc4ad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum purity of 0.8588764044943821 found on random state 71\n",
      "Purity:  0.8588764044943821\n",
      "Sillhouette Coefficient:  0.6609660724161398\n"
     ]
    }
   ],
   "source": [
    "num_topics = 5  # Adjust as needed\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "\n",
    "lda.fit(tfidfMatrix)\n",
    "\n",
    "# Get the topic assignments for each document\n",
    "topic_labels = lda.transform(tfidfMatrix).argmax(axis=1)\n",
    "\n",
    "combined_labels = [lexicalChainsLabels, tfidfLabels, topic_labels]\n",
    "combined_labels = list(map(list, zip(*combined_labels)))\n",
    "\n",
    "normalize_combined_features = Normalizer().fit_transform(combined_labels)\n",
    "topic_purity_collection = {}\n",
    "for i in range(600):\n",
    "    topic_clusters = (KMeans(n_init=\"auto\", n_clusters=5, random_state=i, init=\"k-means++\").fit(normalize_combined_features).labels_)\n",
    "    topic_purity_collection[i] = Purity_Score(label_seq, topic_clusters)\n",
    "\n",
    "topic_max_rand_state = max(topic_purity_collection, key=topic_purity_collection.get)\n",
    "print(f\"Maximum purity of {topic_purity_collection[topic_max_rand_state]} found on random state {topic_max_rand_state}\")\n",
    "max_labels = (KMeans(n_init=\"auto\", n_clusters=5, random_state=topic_max_rand_state, init=\"k-means++\").fit(normalize_combined_features)\n",
    "              .labels_)\n",
    "print(\"Purity: \", Purity_Score(label_seq, max_labels))\n",
    "print(\"Sillhouette Coefficient: \",metrics.silhouette_score(normalize_combined_features, max_labels, metric=\"euclidean\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
