{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'D:\\My Work\\Final Year Project\\Main\\FYP23-Deep-Document-Clustering\\Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from utils.Encoder import Encoder\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.feature_extraction.text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = []  # all the content in the document\n",
    "doc_name = []  # name of the document\n",
    "files_path = []  # path to the documents\n",
    "lexical_chain = []  # list of lexical chains from each document\n",
    "total_features = []  # total number of features. 1652\n",
    "final_training_Features = []\n",
    "corpus = []\n",
    "doc_list_sequence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds(seed):\n",
    "   os.environ['PYTHONHASHSEED']=str(seed)\n",
    "   torch.manual_seed(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "\n",
    "\n",
    "def ReadDocuments(dir_name):\n",
    "    for Path in os.listdir(dir_name):\n",
    "        file_p = os.path.join(dir_name, Path)\n",
    "        with open(file_p, \"r\") as file:\n",
    "            FileContents = file.read()\n",
    "            doc_content.append(FileContents.lower())\n",
    "            doc_name.append(Path)\n",
    "            files_path.append(file_p)\n",
    "\n",
    "def Purity_Score(label_seq, pred_labels):\n",
    "    # Calculate the confusion matrix to compare true labels and cluster assignments\n",
    "    confusion = confusion_matrix(label_seq, pred_labels)\n",
    "    # Calculate the purity\n",
    "    purity = np.sum(np.max(confusion, axis=0)) / np.sum(confusion)\n",
    "    return purity\n",
    "\n",
    "def Evaluate(X, true_labels, predicted_labels):\n",
    "    purity = Purity_Score(true_labels, predicted_labels)\n",
    "    silhouette = silhouette_score(X, predicted_labels, metric='euclidean')\n",
    "    ari = ari_score(true_labels, predicted_labels)\n",
    "    nmi = nmi_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f\"Purity: {purity}\")\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "    print(f\"ARI Score: {ari}\")\n",
    "    print(f\"NMI Score: {nmi}\")\n",
    "\n",
    "def SaveFeatures(X, file_name):\n",
    "    pickle_path = open(file_name, 'wb')\n",
    "    pickle.dump(X, pickle_path)\n",
    "    pickle_path.close()\n",
    "\n",
    "def ReadFeatures(file_name):\n",
    "    pickle_read = open(file_name, 'rb')\n",
    "    x = pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"DOC50_Features/DOC50_TFIDF_Features.pkl\"\n",
    "x = ReadFeatures(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3885)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(shape=(1, x.size()[0], x.size()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 3885])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 3885\n",
    "num_heads = 1\n",
    "drop_prob = 0.1\n",
    "batch_size = 1\n",
    "max_sequence_length = 50\n",
    "ffn_hidden = 2048\n",
    "num_layers = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.PositionalEncoding import PositionalEncoding\n",
    "pe = PositionalEncoding(d_model=d_model, max_sequence_length=max_sequence_length)\n",
    "positional_encoding = pe.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = positional_encoding[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3885])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x + positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(d_model=d_model, ffn_hidden=ffn_hidden, num_heads=num_heads, drop_prob=drop_prob, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00],\n",
      "         [ 8.4147e-01,  5.6684e-01,  8.3891e-01,  ...,  3.3962e-02,\n",
      "           1.0000e+00,  3.3961e-02],\n",
      "         [ 9.0930e-01, -4.1615e-01,  9.1319e-01,  ...,  2.0143e-04,\n",
      "           1.0000e+00,  2.0047e-04],\n",
      "         ...,\n",
      "         [ 1.2357e-01, -9.9234e-01,  3.3934e-01,  ...,  4.7335e-03,\n",
      "           9.9999e-01,  4.7111e-03],\n",
      "         [-7.6825e-01, -6.4014e-01, -6.0443e-01,  ...,  4.8342e-03,\n",
      "           9.9999e-01,  4.8114e-03],\n",
      "         [-9.5375e-01,  3.0059e-01, -9.9730e-01,  ...,  4.9350e-03,\n",
      "           9.9999e-01,  4.9116e-03]]])\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.3659,  0.8104, -0.7150,  ..., -0.6389,  1.7067, -0.0650],\n",
      "         [ 1.2763,  0.0484,  1.1140,  ..., -0.8509,  1.6529, -0.8271],\n",
      "         [ 1.3001, -1.9023,  1.0364,  ..., -0.7808,  1.4033,  0.1862],\n",
      "         ...,\n",
      "         [ 0.3196, -1.9847,  0.0845,  ..., -0.6396,  1.8655, -0.7214],\n",
      "         [-1.3432, -1.8786, -1.2589,  ..., -0.4941,  1.3468, -0.5341],\n",
      "         [-1.2624,  0.3762, -1.8719,  ..., -0.5176,  1.5961, -0.3642]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.8657,  1.1379, -0.4016,  ..., -0.1427,  1.4097, -0.3214],\n",
      "         [ 1.1294,  0.5460,  1.0374,  ..., -0.4189,  1.0426, -0.1632],\n",
      "         [ 1.0390, -1.1016,  1.2319,  ..., -0.1477,  0.7504,  0.7977],\n",
      "         ...,\n",
      "         [ 0.1875, -1.8986, -0.2173,  ..., -0.2504,  1.4697, -0.2361],\n",
      "         [-1.4275, -1.5631, -1.2996,  ..., -0.3893,  0.9781, -0.0160],\n",
      "         [-1.2655,  0.2525, -1.9742,  ..., -0.1078,  1.6376,  0.0820]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.1408, -0.0751, -0.1413,  ..., -0.5036,  1.0218, -0.2544],\n",
      "         [ 1.8292, -0.4517,  1.2509,  ..., -0.4943,  0.7044, -0.1775],\n",
      "         [ 1.6110, -1.9885,  1.3233,  ..., -0.4798,  0.3626,  0.4148],\n",
      "         ...,\n",
      "         [ 0.6660, -2.0037, -0.0294,  ..., -0.5624,  1.0616, -0.3101],\n",
      "         [-1.1018, -1.9453, -1.1563,  ..., -0.4225,  0.5866, -0.2274],\n",
      "         [-1.0363, -0.2778, -1.7780,  ..., -0.2096,  1.2999, -0.0337]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.6392, -0.7831,  0.4939,  ..., -0.8505,  1.0477, -0.2215],\n",
      "         [ 2.2491, -1.1828,  1.5462,  ..., -0.9330,  0.5525, -0.1080],\n",
      "         [ 2.0713, -2.3748,  1.8247,  ..., -0.7348,  0.4806,  0.3272],\n",
      "         ...,\n",
      "         [ 0.9292, -1.9845,  0.4835,  ..., -0.1764,  0.8032, -0.1216],\n",
      "         [-0.6091, -2.2140, -0.4783,  ..., -0.1385,  0.2781, -0.0759],\n",
      "         [-0.6730, -0.4915, -0.8044,  ...,  0.2256,  0.8834,  0.1523]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.2401, -0.7097,  1.2017,  ..., -1.1423,  0.9356, -0.9443],\n",
      "         [ 1.6882, -1.5281,  1.7327,  ..., -1.5386,  0.3857, -0.4932],\n",
      "         [ 1.7558, -1.9254,  2.1621,  ..., -1.3067,  0.2981, -0.2712],\n",
      "         ...,\n",
      "         [ 0.3752, -2.0083,  0.1492,  ..., -0.5275,  0.4199, -0.8483],\n",
      "         [-1.2429, -2.2013, -0.4483,  ...,  0.0337, -0.1642, -0.6457],\n",
      "         [-1.2007, -0.7226, -0.3400,  ...,  0.0416,  0.3813, -0.1920]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 1.2368, -0.6890,  0.7764,  ..., -1.7307,  1.3747, -1.7570],\n",
      "         [ 2.0936, -1.6010,  1.3393,  ..., -1.9342,  0.8067, -1.1375],\n",
      "         [ 2.6108, -1.4388,  1.3990,  ..., -1.5891,  0.7325, -0.9498],\n",
      "         ...,\n",
      "         [ 1.3793, -1.8201, -0.5227,  ..., -0.6399,  0.8618, -1.4044],\n",
      "         [-0.1219, -2.0960, -1.1654,  ..., -0.0911, -0.3474, -1.1979],\n",
      "         [-0.2220, -0.5950, -0.8395,  ..., -0.0252,  0.1572, -0.8165]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.8207, -0.1546,  1.2689,  ..., -1.9442,  1.0413, -1.6439],\n",
      "         [ 1.6627, -1.0176,  1.6199,  ..., -1.8875,  0.3002, -0.7770],\n",
      "         [ 2.0697, -0.7410,  1.2473,  ..., -1.6615,  0.2280, -0.5776],\n",
      "         ...,\n",
      "         [ 0.9196, -1.4579, -0.4079,  ..., -1.1074,  0.8177, -1.0062],\n",
      "         [-0.6447, -1.5247, -1.0347,  ..., -0.6824, -0.2584, -1.0724],\n",
      "         [-0.6975, -0.7625, -1.1163,  ..., -0.7049,  0.1669, -0.1212]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.9501, -0.4410,  2.1546,  ..., -1.7902,  1.4615, -0.4868],\n",
      "         [ 1.6819, -1.4561,  2.3378,  ..., -1.6948,  0.8158,  0.1924],\n",
      "         [ 2.0377, -1.1073,  1.7720,  ..., -1.5792,  0.6234,  0.4246],\n",
      "         ...,\n",
      "         [ 0.9498, -1.8512,  0.3067,  ..., -0.9726,  1.1376, -0.5028],\n",
      "         [-1.4577, -1.7738, -0.2028,  ..., -0.5598, -0.0643, -0.4981],\n",
      "         [-1.4302, -0.5661, -0.3898,  ..., -0.8852,  0.3399,  0.3464]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.6268, -0.0401,  2.0704,  ..., -2.0869,  1.0044, -0.2158],\n",
      "         [ 1.3735, -1.2584,  2.5024,  ..., -1.9270,  0.7576,  0.5234],\n",
      "         [ 1.7001, -0.5787,  1.6704,  ..., -1.8839,  0.5693,  0.4504],\n",
      "         ...,\n",
      "         [ 0.3384, -1.8352,  0.5891,  ..., -1.1063,  1.2923, -0.5352],\n",
      "         [-1.6484, -1.9709,  0.4172,  ..., -0.5738,  0.3169, -0.4322],\n",
      "         [-1.4312, -0.7391,  0.3713,  ..., -1.0566,  0.2767,  0.4068]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.5675, -0.2009,  2.0901,  ..., -1.8417,  0.4361, -0.1982],\n",
      "         [ 1.1776, -1.5954,  2.1239,  ..., -1.5402,  0.1446,  0.5742],\n",
      "         [ 1.9528, -0.7602,  1.5230,  ..., -1.2709, -0.3977,  0.1762],\n",
      "         ...,\n",
      "         [ 0.6680, -1.7483,  0.6660,  ..., -0.6502,  1.0082, -0.2861],\n",
      "         [-1.2905, -2.0994,  0.4960,  ..., -0.4363,  0.0119, -0.3285],\n",
      "         [-0.9735, -0.8717,  0.5233,  ..., -0.8590, -0.0167,  0.3255]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 1.2097, -0.3585,  1.6413,  ..., -2.3935,  0.0899,  0.6714],\n",
      "         [ 1.2006, -1.6531,  1.2922,  ..., -2.4269,  0.0800,  1.2440],\n",
      "         [ 2.3812, -0.7527,  0.6332,  ..., -2.1568, -0.8164,  0.4104],\n",
      "         ...,\n",
      "         [ 0.9023, -2.2368,  0.0835,  ..., -0.9655,  1.0368,  0.4981],\n",
      "         [-0.6744, -2.2553,  0.3707,  ..., -1.1504,  0.0945,  0.1065],\n",
      "         [-0.4924, -1.3108,  0.2908,  ..., -1.6597,  0.0124,  0.9698]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.7773, -0.2697,  1.1713,  ..., -1.9203,  0.4591,  0.3954],\n",
      "         [ 0.8374, -1.0725,  0.5283,  ..., -2.2515,  0.4690,  0.7586],\n",
      "         [ 1.6504, -0.1559, -0.0562,  ..., -1.7431, -0.6897, -0.1277],\n",
      "         ...,\n",
      "         [ 1.0962, -2.2256, -0.5205,  ..., -0.3583,  1.4992, -0.2716],\n",
      "         [-0.6972, -2.2776,  0.2619,  ..., -0.6414,  0.8657,  0.1779],\n",
      "         [-0.2404, -1.3108,  0.1737,  ..., -1.3704,  0.3666,  0.0413]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 1.5406, -0.5733,  1.0330,  ..., -1.4218,  1.3674,  0.7668],\n",
      "         [ 1.3345, -1.2196,  0.7306,  ..., -1.8147,  1.0144,  0.8935],\n",
      "         [ 2.3151, -0.5893, -0.0926,  ..., -1.3126, -0.1335,  0.1989],\n",
      "         ...,\n",
      "         [ 1.4484, -2.4754, -0.1312,  ..., -0.0235,  1.5834, -0.5734],\n",
      "         [-0.3335, -2.0066,  0.5043,  ..., -0.5520,  0.5186, -0.0311],\n",
      "         [ 0.2863, -1.1838,  0.3118,  ..., -1.0758,  0.6866,  0.1047]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 2.0346, -1.7824,  0.5600,  ..., -1.6072,  1.2811,  0.1644],\n",
      "         [ 1.8127, -2.2590,  0.6767,  ..., -1.8779,  1.2792,  0.0974],\n",
      "         [ 3.0316, -1.1324,  0.2552,  ..., -1.0972,  0.1981, -0.8098],\n",
      "         ...,\n",
      "         [ 1.4267, -3.0657,  0.1514,  ...,  0.0061,  2.0477, -1.0891],\n",
      "         [-0.3109, -2.5809,  0.7429,  ..., -0.4255,  0.8355, -0.3570],\n",
      "         [ 0.2895, -1.5126,  0.5691,  ..., -1.1600,  0.9417, -0.1218]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 1.7797, -1.8279,  1.0017,  ..., -1.7856,  0.8830,  0.0414],\n",
      "         [ 1.5091, -2.3861,  0.8449,  ..., -1.8210,  0.9064,  0.4377],\n",
      "         [ 2.8599, -0.9689,  0.4817,  ..., -0.9620,  0.2993, -0.3365],\n",
      "         ...,\n",
      "         [ 1.3165, -2.7838,  0.7346,  ..., -0.3463,  1.7708, -0.5033],\n",
      "         [-0.6968, -2.5035,  0.9817,  ..., -1.0040,  0.6817,  0.2375],\n",
      "         [-0.0969, -1.1446,  1.0098,  ..., -1.2981,  0.7047,  0.3504]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 1.0669, -2.3200,  0.4283,  ..., -1.9807,  1.2099, -0.0708],\n",
      "         [ 0.7367, -2.5516,  0.3249,  ..., -2.1985,  1.0138, -0.1182],\n",
      "         [ 2.0862, -1.6206, -0.0738,  ..., -1.4428,  0.0296, -0.7913],\n",
      "         ...,\n",
      "         [ 0.8506, -3.4719,  0.0840,  ..., -0.1814,  1.7172, -0.8427],\n",
      "         [-0.9044, -2.9138,  0.2742,  ..., -0.6195,  0.8241, -0.1741],\n",
      "         [-0.7004, -1.5113,  0.7829,  ..., -1.0074,  0.7302, -0.0452]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.9507, -1.8403,  0.5856,  ..., -1.9020,  0.7138, -0.1601],\n",
      "         [ 0.7442, -2.1257,  0.5084,  ..., -1.9911,  0.9526, -0.3468],\n",
      "         [ 2.0581, -1.7209,  0.0690,  ..., -1.1386, -0.1215, -0.6610],\n",
      "         ...,\n",
      "         [ 0.8075, -2.7900, -0.3637,  ...,  0.0516,  1.5581, -0.6364],\n",
      "         [-0.7003, -2.3733, -0.0037,  ..., -0.2266,  0.5214,  0.0240],\n",
      "         [-0.4668, -0.8827,  0.3935,  ..., -0.7036,  0.3769, -0.0203]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.6292, -1.6257,  0.0212,  ..., -2.1983,  0.6481, -0.4188],\n",
      "         [ 0.6750, -1.6684,  0.2820,  ..., -2.2028,  0.8581, -0.2261],\n",
      "         [ 2.2465, -1.5321, -0.3594,  ..., -1.6075, -0.1854, -0.7302],\n",
      "         ...,\n",
      "         [ 0.6454, -1.6097, -0.7800,  ..., -0.1210,  1.3521, -0.8503],\n",
      "         [-0.5562, -1.6324, -0.3205,  ..., -0.4134,  0.4764, -0.2317],\n",
      "         [-0.0171, -0.3299,  0.3087,  ..., -1.0422,  0.3484, -0.2683]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.1613, -1.3963,  0.3409,  ..., -1.8734,  0.6208,  0.1548],\n",
      "         [-0.3409, -1.6370,  0.5099,  ..., -2.0639,  0.5036, -0.0028],\n",
      "         [ 0.9769, -1.3286, -0.1910,  ..., -1.3989, -0.6040, -0.4204],\n",
      "         ...,\n",
      "         [-0.4566, -1.2117, -0.8898,  ..., -0.4139,  0.8507, -1.3651],\n",
      "         [-1.4720, -1.3766, -0.2990,  ..., -0.1846,  0.3187, -0.7253],\n",
      "         [-0.8446, -0.4428,  0.2262,  ..., -1.0910,  0.0498, -0.7791]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.0873, -1.3551,  0.2554,  ..., -1.9517,  0.6423, -0.9196],\n",
      "         [-0.2295, -1.5215,  0.3680,  ..., -2.1596,  0.8036, -1.3675],\n",
      "         [ 1.0638, -1.0975, -0.5945,  ..., -1.9524, -0.7989, -0.9274],\n",
      "         ...,\n",
      "         [ 0.1015, -1.1069, -1.1377,  ..., -0.6499,  0.6676, -1.6088],\n",
      "         [-1.1896, -1.4987, -0.6810,  ..., -0.6229,  0.0193, -1.1461],\n",
      "         [-0.4552, -0.3411, -0.1891,  ..., -1.3613, -0.0911, -1.1106]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.4521, -1.5096, -0.3017,  ..., -2.3081,  1.0373, -0.5837],\n",
      "         [-0.1715, -2.4273,  0.0804,  ..., -2.4414,  1.2791, -0.9272],\n",
      "         [ 1.4588, -2.3241, -0.8222,  ..., -2.0143, -0.1583, -0.4144],\n",
      "         ...,\n",
      "         [-0.0195, -1.6001, -1.2537,  ..., -0.5580,  1.1139, -1.4906],\n",
      "         [-0.8197, -2.4018, -0.9233,  ..., -0.7307,  0.3667, -0.7631],\n",
      "         [-0.0397, -1.5182, -0.2586,  ..., -1.3612, -0.2676, -0.6788]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.2043, -2.3059, -0.5208,  ..., -2.1673,  0.9517, -0.0788],\n",
      "         [-0.6387, -3.2787, -0.0956,  ..., -2.2063,  1.2489, -0.8158],\n",
      "         [ 1.2826, -2.7971, -0.9669,  ..., -2.0978, -0.3929, -0.2797],\n",
      "         ...,\n",
      "         [-0.1653, -1.6726, -1.1179,  ..., -0.8554,  0.6566, -1.2854],\n",
      "         [-1.2849, -2.8270, -0.9413,  ..., -1.0734,  0.2155, -0.5877],\n",
      "         [-0.6336, -2.1757, -0.3024,  ..., -1.4422, -0.3387, -0.3968]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.3601, -1.6098, -0.5000,  ..., -2.3330,  0.5176,  0.1016],\n",
      "         [-0.5477, -2.4967, -0.1845,  ..., -2.1563,  0.9677, -0.6183],\n",
      "         [ 0.8868, -1.9150, -1.0229,  ..., -1.8940, -0.4281,  0.2381],\n",
      "         ...,\n",
      "         [-0.4115, -0.8879, -0.9202,  ..., -1.2950,  1.0265, -0.7861],\n",
      "         [-1.7091, -2.1118, -0.8344,  ..., -1.1886,  0.2044, -0.2859],\n",
      "         [-0.8254, -1.3912, -0.4720,  ..., -1.8319, -0.0142, -0.1873]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.3561, -1.8595,  0.1066,  ..., -2.1035, -0.6123, -0.4072],\n",
      "         [-0.4945, -2.5532,  0.2239,  ..., -2.0108,  1.0031, -1.0676],\n",
      "         [ 0.6831, -2.0134, -0.8392,  ..., -1.9314, -1.0235, -0.1029],\n",
      "         ...,\n",
      "         [-0.9588, -1.1145, -0.3217,  ..., -1.2194,  1.1310, -1.2731],\n",
      "         [-1.6499, -2.2509, -0.2981,  ..., -0.9619,  0.2891, -0.7648],\n",
      "         [-1.4207, -1.7754, -0.0388,  ..., -1.6349, -0.0577, -0.7024]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.5537, -1.5339, -0.0567,  ..., -2.0771, -0.5847, -0.7762],\n",
      "         [-0.4550, -2.3272, -0.1630,  ..., -1.6557,  0.6535, -1.5563],\n",
      "         [ 0.9016, -1.7760, -1.3377,  ..., -1.5874, -1.0659, -0.4046],\n",
      "         ...,\n",
      "         [-0.8732, -0.5019, -0.9289,  ..., -0.8765,  1.1787, -1.8023],\n",
      "         [-1.5980, -1.6304, -0.7816,  ..., -0.6128,  0.4145, -1.0242],\n",
      "         [-1.3204, -1.1438, -0.4954,  ..., -1.2002, -0.0400, -1.0592]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.2283, -1.8540, -0.3483,  ..., -2.2940, -0.6767, -0.0508],\n",
      "         [-0.3980, -2.9955, -0.2692,  ..., -1.7988,  0.8201, -0.7601],\n",
      "         [ 0.9054, -2.1641, -1.3843,  ..., -1.4696, -0.8910,  0.2650],\n",
      "         ...,\n",
      "         [-0.5932, -0.6111, -0.9524,  ..., -1.2002,  1.5258, -1.3382],\n",
      "         [-1.5921, -1.5134, -0.7274,  ..., -0.9290,  0.5626, -0.4264],\n",
      "         [-1.3305, -1.3597, -0.4589,  ..., -1.5843,  0.4220, -0.4072]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.2918, -1.2040,  0.1916,  ..., -1.8366, -0.9205,  0.1991],\n",
      "         [-0.3052, -2.4954,  0.7934,  ..., -1.1497,  0.4430, -0.7575],\n",
      "         [ 0.9064, -1.6188, -0.4947,  ..., -0.8567, -1.2637,  0.6089],\n",
      "         ...,\n",
      "         [-0.3168, -0.6603, -0.5390,  ..., -0.8609,  1.5359, -1.1841],\n",
      "         [-1.4107, -1.6184, -0.4265,  ..., -0.8942,  0.2857, -0.3327],\n",
      "         [-0.8583, -1.2163, -0.0454,  ..., -1.2295,  0.4588, -0.1226]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.1797, -1.3250, -0.3084,  ..., -1.9382, -0.7259, -0.3794],\n",
      "         [-0.2144, -2.4637,  0.2232,  ..., -1.6354,  0.9837, -0.8857],\n",
      "         [ 1.2184, -1.2837, -0.9630,  ..., -1.4222, -1.3206,  0.0560],\n",
      "         ...,\n",
      "         [ 0.2082, -0.7039, -0.5548,  ..., -1.2602,  1.2002, -1.7854],\n",
      "         [-0.9244, -1.9365, -0.9441,  ..., -1.4281,  0.2558, -1.0089],\n",
      "         [-0.7947, -1.3780,  0.0869,  ..., -1.5996,  0.5224, -0.7355]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.5203, -1.2226, -0.5948,  ..., -1.5190, -0.9270, -0.5716],\n",
      "         [ 0.2975, -2.4733, -0.2330,  ..., -1.2626,  0.7939, -1.3047],\n",
      "         [ 1.6368, -1.1587, -1.0399,  ..., -0.9116, -1.2731, -0.1652],\n",
      "         ...,\n",
      "         [ 0.3955, -0.5077, -0.9911,  ..., -1.2217,  1.3318, -2.1150],\n",
      "         [-0.5683, -2.0210, -1.3587,  ..., -1.1183,  0.6401, -1.1146],\n",
      "         [-0.1775, -1.4701, -0.5673,  ..., -1.2393,  0.6364, -0.9112]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "out = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_Labels(X, n, rstate_limit, true_labels):\n",
    "    print(X)\n",
    "    # Specify the number of clusters (you can choose an appropriate value)\n",
    "    num_clusters = n\n",
    "    \n",
    "    # find centoids which give maximum purity\n",
    "    purity_collection = {}\n",
    "    for i in range(rstate_limit):\n",
    "        clusters = KMeans(n_init='auto', n_clusters=num_clusters, random_state=i, init='k-means++').fit(X).labels_\n",
    "        purity_collection[i] = Purity_Score(true_labels, clusters)\n",
    "    \n",
    "    max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "    print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "\n",
    "    # Create a KMeans model\n",
    "    kmeans = KMeans(n_init='auto', n_clusters=num_clusters, random_state=max_rand_state, init='k-means++')\n",
    "    # Fit the KMeans model to the TF-IDF data\n",
    "    kmeans.fit(X)\n",
    "    # Get the cluster assignments for each document\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    \n",
    "    return cluster_assignments\n",
    "\n",
    "def Actual_Labels():\n",
    "    ReadDocuments(os.getcwd() + \"\\Doc50\")\n",
    "    actual_labels = {} # dictionary to store true assignments for each document | read sequence not followed\n",
    "    label_path = os.getcwd() + '\\\\Doc50 GT\\\\'\n",
    "    for labels_directory in os.listdir(label_path): # for each assignment folder\n",
    "        actual_cluster = int(labels_directory[1]) # extract cluster label from directory name\n",
    "        doc_labels = os.listdir(label_path + f\"\\\\{labels_directory}\") # for all document ids assigned to this cluster\n",
    "        for doc in doc_labels:\n",
    "            actual_labels[doc] = actual_cluster-1 # save cluster label\n",
    "    \n",
    "    label_seq = [] # save labels in order of documents read\n",
    "    for doc in doc_name:\n",
    "        label_seq.append(actual_labels[doc])\n",
    "    return label_seq\n",
    "\n",
    "def print_results(true_labels, predicted_labels, X):\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"Purity: {Purity_Score(true_labels, predicted_labels)}\")\n",
    "    print(f\"Silhouette Score: {silhouette_score(X, predicted_labels)}\")\n",
    "\n",
    "\n",
    "def wrapperFunction():\n",
    "    # ReadDocuments('Doc50')\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', preprocessor=custom_preprocessor)\n",
    "    X = vectorizer.fit_transform(doc_content)\n",
    "\n",
    "    SaveFeatures(X, 'DOC50_TFIDF_Features.pkl')\n",
    "    \n",
    "    true_labels = Actual_Labels()\n",
    "    predicted_labels = KMeans_Labels(X, 5, 1500, true_labels)\n",
    "    Evaluate(X, true_labels, predicted_labels)\n",
    "    return predicted_labels, X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_x = out.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3885)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = []  # all the content in the document\n",
    "doc_name = []  # name of the document\n",
    "files_path = []  # path to the documents\n",
    "lexical_chain = []  # list of lexical chains from each document\n",
    "total_features = []  # total number of features. 1652\n",
    "final_training_Features = []\n",
    "corpus = []\n",
    "doc_list_sequence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22546476 -0.752269   -0.2797785  ... -1.6128085  -0.86013365\n",
      "  -0.50368404]\n",
      " [ 0.23896243 -1.9640815  -0.22243536 ... -1.8387103   0.96590763\n",
      "  -0.9953801 ]\n",
      " [ 1.5015172  -0.8540485  -0.70489764 ... -0.60399705 -0.7053957\n",
      "  -0.3041028 ]\n",
      " ...\n",
      " [ 0.3390127  -0.3497321  -0.73360956 ... -1.7436712   1.2708973\n",
      "  -2.2900813 ]\n",
      " [-0.33624384 -1.62918    -0.90313387 ... -1.5827706   0.40459463\n",
      "  -1.3033046 ]\n",
      " [-0.11811316 -0.96314085  0.02694708 ... -1.8406849   0.39085737\n",
      "  -1.0530618 ]]\n",
      "Maximum purity of 0.9 found on random state 338\n"
     ]
    }
   ],
   "source": [
    "true_labels = Actual_Labels()\n",
    "pred_lables = KMeans_Labels(enhanced_x[0], 5, 700, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.9\n",
      "Silhouette Score: 0.02138533629477024\n",
      "ARI Score: 0.7606082230883241\n",
      "NMI Score: 0.8141170603643352\n"
     ]
    }
   ],
   "source": [
    "Evaluate(enhanced_x[0], true_labels, pred_lables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
