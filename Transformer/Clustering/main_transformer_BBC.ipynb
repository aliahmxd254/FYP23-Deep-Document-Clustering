{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'D:\\My Work\\Final Year Project\\Main\\FYP23-Deep-Document-Clustering\\Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faizan\\AppData\\Local\\Temp\\ipykernel_3900\\2610695767.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "C:\\Users\\Faizan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from utils.Encoder import Encoder\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.feature_extraction.text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds(seed):\n",
    "   os.environ['PYTHONHASHSEED']=str(seed)\n",
    "   torch.manual_seed(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "\n",
    "def Purity_Score(label_seq, pred_labels):\n",
    "    # Calculate the confusion matrix to compare true labels and cluster assignments\n",
    "    confusion = confusion_matrix(label_seq, pred_labels)\n",
    "    # Calculate the purity\n",
    "    purity = np.sum(np.max(confusion, axis=0)) / np.sum(confusion)\n",
    "    return purity\n",
    "\n",
    "def Evaluate(X, true_labels, predicted_labels):\n",
    "    purity = Purity_Score(true_labels, predicted_labels)\n",
    "    silhouette = silhouette_score(X, predicted_labels, metric='euclidean')\n",
    "    ari = ari_score(true_labels, predicted_labels)\n",
    "    nmi = nmi_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f\"Purity: {purity}\")\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "    print(f\"ARI Score: {ari}\")\n",
    "    print(f\"NMI Score: {nmi}\")\n",
    "\n",
    "def SaveFeatures(X, file_name):\n",
    "    pickle_path = open(file_name, 'wb')\n",
    "    pickle.dump(X, pickle_path)\n",
    "    pickle_path.close()\n",
    "\n",
    "def ReadFeatures(file_name):\n",
    "    pickle_read = open(file_name, 'rb')\n",
    "    x = pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt('bbc.txt', dtype=float)\n",
    "y = np.loadtxt('bbc_label.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2225, 9635])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(shape=(1, x.size()[0], x.size()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 9635\n",
    "num_heads = 1\n",
    "drop_prob = 0.1\n",
    "batch_size = 1\n",
    "max_sequence_length = 2225\n",
    "ffn_hidden = 2048\n",
    "num_layers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2225, 9635])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.PositionalEncoding import PositionalEncoding\n",
    "pe = PositionalEncoding(d_model=d_model, max_sequence_length=max_sequence_length)\n",
    "positional_encoding = pe.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2225, 9635])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding = positional_encoding[:,0:-1]\n",
    "positional_encoding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x + positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(d_model=d_model, ffn_hidden=ffn_hidden, num_heads=num_heads, drop_prob=drop_prob, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[ 2.6300e-02,  1.0792e+00,  1.0320e-01,  ...,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  8.9384e-01,  ...,  1.0029e-04,\n",
      "           1.0000e+00,  1.0010e-04],\n",
      "         [ 9.0930e-01, -3.4795e-01,  9.1088e-01,  ...,  2.0057e-04,\n",
      "           1.0000e+00,  2.0019e-04],\n",
      "         ...,\n",
      "         [-7.7958e-01, -6.2630e-01, -2.0705e-01,  ...,  2.2100e-01,\n",
      "           9.7527e-01,  2.2058e-01],\n",
      "         [-9.4822e-01,  3.1760e-01,  7.1017e-01,  ...,  2.2110e-01,\n",
      "           9.7525e-01,  2.2068e-01],\n",
      "         [-2.4508e-01,  9.8140e-01,  9.7655e-01,  ...,  2.2119e-01,\n",
      "           9.7523e-01,  2.2078e-01]]])\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-1.0872,  0.8504, -1.1078,  ..., -1.1808,  0.4240, -0.6857],\n",
      "         [ 0.2411, -0.1746,  0.4309,  ..., -1.3071,  0.4352, -0.8905],\n",
      "         [ 0.5909, -2.0414,  0.5199,  ..., -1.1936,  0.4812, -0.7442],\n",
      "         ...,\n",
      "         [-1.3328, -1.4119, -0.6200,  ..., -0.0703,  1.2607,  0.5153],\n",
      "         [-1.5403, -0.0939,  0.7899,  ..., -0.0274,  1.5253,  0.4851],\n",
      "         [-0.3063,  0.9328,  1.1809,  ...,  0.0273,  1.2273,  0.3005]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-1.1740e+00,  7.4268e-01, -1.4351e+00,  ..., -1.7325e+00,\n",
      "           6.1785e-01, -1.1999e+00],\n",
      "         [-1.2985e-01, -1.4088e-01,  1.7043e-01,  ..., -1.2931e+00,\n",
      "           6.6285e-01, -1.7467e+00],\n",
      "         [ 5.4576e-01, -2.1889e+00,  9.1639e-02,  ..., -1.9617e+00,\n",
      "           8.9425e-01, -1.4564e+00],\n",
      "         ...,\n",
      "         [-1.9479e+00, -1.4891e+00, -6.1217e-01,  ..., -6.8212e-02,\n",
      "           1.2457e+00, -1.3289e-03],\n",
      "         [-2.2339e+00,  1.4133e-01,  7.0525e-01,  ..., -5.2861e-01,\n",
      "           1.3303e+00, -1.6722e-01],\n",
      "         [-8.5335e-01,  1.0813e+00,  1.0485e+00,  ..., -5.9184e-01,\n",
      "           1.1271e+00, -3.8105e-01]]], grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-0.7193, -0.0794, -1.5086,  ..., -1.3589,  0.8568, -1.2303],\n",
      "         [ 0.2498, -0.7102, -0.1043,  ..., -1.1535,  1.3042, -1.6290],\n",
      "         [ 1.1232, -2.2963, -0.1609,  ..., -2.0428,  0.9673, -1.3923],\n",
      "         ...,\n",
      "         [-2.3633, -1.9513, -0.7544,  ..., -0.3420,  1.0508, -0.3043],\n",
      "         [-2.4791, -0.4269,  0.1801,  ..., -0.5362,  1.0336, -0.5145],\n",
      "         [-1.2600,  0.4972,  0.8542,  ..., -0.5949,  0.9916, -0.3217]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-0.8309,  0.1643, -1.7246,  ..., -1.4232,  1.6158, -1.7523],\n",
      "         [ 0.0640, -0.8410, -0.5736,  ..., -1.0899,  1.3515, -1.7203],\n",
      "         [ 0.7149, -1.9300, -0.7797,  ..., -1.8660,  1.5971, -1.4793],\n",
      "         ...,\n",
      "         [-2.2523, -1.8354, -1.1898,  ..., -0.1659,  0.8702, -0.2645],\n",
      "         [-2.0780, -0.2594, -0.3225,  ..., -0.5635,  1.1050, -0.2110],\n",
      "         [-1.2139,  0.4034,  1.1363,  ..., -0.7081,  0.8069, -0.2550]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-0.6870,  0.0386, -1.9038,  ..., -1.3356,  1.7916, -1.5547],\n",
      "         [ 0.3457, -1.0021, -0.3424,  ..., -0.9809,  1.0323, -1.5761],\n",
      "         [ 1.1388, -1.7454, -1.1758,  ..., -1.8619,  1.5804, -1.7367],\n",
      "         ...,\n",
      "         [-2.0024, -1.7548, -0.6658,  ..., -0.1470,  0.6221, -0.9879],\n",
      "         [-1.9813, -0.0986,  0.1971,  ..., -0.2789,  0.9960, -0.8543],\n",
      "         [-0.9078,  0.3006,  1.4667,  ..., -0.4729,  0.5911, -0.6982]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-0.6403,  0.2251, -2.1202,  ..., -1.0126,  1.8408, -1.6679],\n",
      "         [ 0.2032, -0.7285, -0.5003,  ..., -0.7557,  1.2019, -1.4964],\n",
      "         [ 1.2805, -1.3726, -1.3388,  ..., -1.6289,  1.9603, -1.5303],\n",
      "         ...,\n",
      "         [-1.6470, -1.4245, -0.3476,  ..., -0.0439,  0.9988, -1.6936],\n",
      "         [-1.7364,  0.4292,  0.4197,  ..., -0.0566,  1.3104, -1.3939],\n",
      "         [-0.7812,  0.3726,  1.2784,  ..., -0.3649,  0.8856, -1.3953]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-0.2286,  0.0782, -2.4261,  ..., -1.3591,  1.6879, -1.6193],\n",
      "         [ 0.5706, -0.4362, -0.9936,  ..., -1.2090,  0.6791, -1.8082],\n",
      "         [ 1.4126, -1.5839, -1.7793,  ..., -1.7240,  1.2575, -1.8803],\n",
      "         ...,\n",
      "         [-1.5301, -1.1952, -0.1774,  ...,  0.2039,  0.5133, -1.3482],\n",
      "         [-1.4984,  0.2485,  0.2538,  ...,  0.3539,  0.8439, -1.3750],\n",
      "         [-0.6957,  0.2309,  1.1239,  ..., -0.1830,  0.1667, -1.1942]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-0.6543,  0.0234, -2.7144,  ..., -1.0836,  1.4693, -1.3956],\n",
      "         [-0.2537, -0.3490, -0.9151,  ..., -1.0182,  0.5070, -1.2694],\n",
      "         [ 0.6672, -1.4907, -2.3229,  ..., -1.6473,  1.1127, -1.7112],\n",
      "         ...,\n",
      "         [-2.4391, -1.3101, -0.6088,  ...,  0.5777,  0.2040, -0.9755],\n",
      "         [-2.0709,  0.4729, -0.2226,  ...,  0.7018,  0.6668, -0.6637],\n",
      "         [-1.5088,  0.2631,  0.6836,  ...,  0.0928, -0.0750, -0.9953]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n",
      "x.size(): torch.Size([1, 2225, 9635])\n",
      "tensor([[[-0.8590,  0.0625, -2.3094,  ..., -1.0558,  1.4150, -0.7171],\n",
      "         [-0.4936,  0.1203, -0.8467,  ..., -0.8732,  0.8479, -0.6509],\n",
      "         [ 0.4336, -1.1009, -1.9260,  ..., -1.6627,  1.3589, -1.0243],\n",
      "         ...,\n",
      "         [-2.2656, -0.6433, -0.0298,  ...,  0.8593,  0.2527, -1.1522],\n",
      "         [-2.0131,  0.6546,  0.1821,  ...,  1.1071,  0.3624, -0.8779],\n",
      "         [-1.3706,  0.6948,  0.5425,  ...,  0.6642, -0.0181, -0.8006]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 2225, 28905])\n",
      "1, 2225, 1, 9635\n",
      "qkv.size(): torch.Size([1, 2225, 1, 28905])\n",
      "q.size(): torch.Size([1, 1, 2225, 9635]), k.size(): torch.Size([1, 1, 2225, 9635]), v.size(): torch.Size([1, 1, 2225, 9635])\n",
      "values.size(): torch.Size([1, 1, 2225, 9635]), attention.size(): torch.Size([1, 1, 2225, 2225])\n"
     ]
    }
   ],
   "source": [
    "out = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_Labels(X, n, rstate_limit, true_labels):\n",
    "    # Specify the number of clusters (you can choose an appropriate value)\n",
    "    num_clusters = n\n",
    "    \n",
    "    # find centoids which give maximum purity\n",
    "    purity_collection = {}\n",
    "    for i in range(rstate_limit):\n",
    "        clusters = KMeans(n_init='auto', n_clusters=num_clusters, random_state=i, init='k-means++').fit(X).labels_\n",
    "        purity_collection[i] = Purity_Score(true_labels, clusters)\n",
    "    \n",
    "    max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "    print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "\n",
    "    # Create a KMeans model\n",
    "    kmeans = KMeans(n_init='auto', n_clusters=num_clusters, random_state=max_rand_state, init='k-means++')\n",
    "    # Fit the KMeans model to the TF-IDF data\n",
    "    kmeans.fit(X)\n",
    "    # Get the cluster assignments for each document\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    \n",
    "    return cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4829814  -0.30550644 -2.6516962  ... -0.27367076  1.0434115\n",
      "  -0.1667899 ]\n",
      " [-0.7777049  -0.36999097 -1.2766799  ... -0.6501163   0.7576171\n",
      "  -0.4635597 ]\n",
      " [ 0.09600183 -1.6981431  -2.1667325  ... -1.2274513   0.816791\n",
      "  -0.53556496]\n",
      " ...\n",
      " [-2.5809865  -1.1995898   0.02883495 ...  0.9508646  -0.26006764\n",
      "  -0.6930991 ]\n",
      " [-2.0074213   0.51819694  0.20549996 ...  0.9733817  -0.05098412\n",
      "  -0.540231  ]\n",
      " [-1.506138    0.07542907  0.51014477 ...  0.7031725  -0.5116253\n",
      "  -0.5572052 ]]\n",
      "Maximum purity of 0.9267415730337079 found on random state 199\n"
     ]
    }
   ],
   "source": [
    "enhanced_x = out.detach().numpy()\n",
    "true_labels = y\n",
    "pred_lables = KMeans_Labels(enhanced_x[0], 5, 700, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.9267415730337079\n",
      "Silhouette Score: 0.07887065410614014\n",
      "ARI Score: 0.831234633058411\n",
      "NMI Score: 0.8632482451556426\n"
     ]
    }
   ],
   "source": [
    "Evaluate(enhanced_x[0], true_labels, pred_lables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
